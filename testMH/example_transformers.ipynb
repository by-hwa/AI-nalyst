{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a2c7b9b5-4e87-4a61-992f-60730923bd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "# from tqdm import tqdm, tqdm_notebook\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from datasets import load_dataset, load_metric, load_from_disk\n",
    "# from transformers import TrainingArguments, Trainer\n",
    "# from transformers import DataCollatorWithPadding, EarlyStoppingCallback, AdamW\n",
    "\n",
    "# import random\n",
    "# import numpy as np\n",
    "# import gluonnlp as nlp\n",
    "# from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "# from kobert.utils import get_tokenizer\n",
    "# from kobert.pytorch_kobert import get_pytorch_kobert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84fc6373-8786-4f79-bf9c-a504f07f33c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>article</th>\n",
       "      <th>length</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>311.txt</td>\n",
       "      <td>하지만 이번 경기 Cycle 에는 이자유예, 양극화 등 여러 요인으로 자산건전성이 ...</td>\n",
       "      <td>363</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>strongbuy465.txt</td>\n",
       "      <td>오직 우려되는 사항은 해외 플랜트 부문의 실적이 언제쯤 개선될지다. 이번 2Q16 ...</td>\n",
       "      <td>283</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>strongbuy164.txt</td>\n",
       "      <td>투자의견 STRONG BUY 유지, 목표주가 146,000원으로 상향 한국항공우주 ...</td>\n",
       "      <td>397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>보유하향59.txt</td>\n",
       "      <td>목표주가 하향조정하며 HOLD 투자의견 유지: 이익전망 미세조정에도 불구 목표주가는...</td>\n",
       "      <td>313</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>strongbuy301.txt</td>\n",
       "      <td>‘the’ 기록적인 실적 3Q15 Review: 매출 7,040억원, 영업이익 79...</td>\n",
       "      <td>1203</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename                                            article  \\\n",
       "0           311.txt  하지만 이번 경기 Cycle 에는 이자유예, 양극화 등 여러 요인으로 자산건전성이 ...   \n",
       "1  strongbuy465.txt  오직 우려되는 사항은 해외 플랜트 부문의 실적이 언제쯤 개선될지다. 이번 2Q16 ...   \n",
       "2  strongbuy164.txt  투자의견 STRONG BUY 유지, 목표주가 146,000원으로 상향 한국항공우주 ...   \n",
       "3        보유하향59.txt  목표주가 하향조정하며 HOLD 투자의견 유지: 이익전망 미세조정에도 불구 목표주가는...   \n",
       "4  strongbuy301.txt  ‘the’ 기록적인 실적 3Q15 Review: 매출 7,040억원, 영업이익 79...   \n",
       "\n",
       "   length  label  \n",
       "0     363      0  \n",
       "1     283      1  \n",
       "2     397      1  \n",
       "3     313      0  \n",
       "4    1203      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train_report.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "df2662c0-9190-43f6-8cdf-7878876eb7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"skt/kobert-base-v1\"\n",
    "model = AutoModel.from_pretrained(checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "79bea89e-8a62-47ce-8451-d2bd584b0780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertModel(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (token_type_embeddings): Embedding(2, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "# print('-'*100)\n",
    "# print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f55c9c7f-004a-47d5-9267-3d62d3edb976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: 395 \n",
      "투자의견 STRONG BUY 유지, 목표주가 146,000원으로 상향 한국항공우주 투자의견 STRONG BUY를 유지하며, 목표주가는 기존 115,000원에서 27.0% 상향 조정한 146,000원으로 수정 제시한다. 목표주가 상향근거는 ROE 상향(21.2%22.7%)에 따른 적용 밸류에이션 상향(PBR 5.3 -> 6.8배)에 기인한다. 2Q16 실적을 통해 연간 두 자리대의 영업이익률을 충분히 기록할 수 있음이 확인되었기 때문에 가능한 목표주가 상향이다. 2011년 상장 이후 짝수년도의 신규수주는 홀수년도 대비 부진했다. 현재는 실적 증가에 관심을 둘 때일 뿐, 수주는 2017년 다시 기대하는 것이 타당한 시점이다. 현재주가는 2016년 실적추정치 기준 PER 29.0배, PBR 5.6배다.\n",
      "\n",
      "After kobert_tokenize\n",
      "length: 396 \n",
      "['▁', '투자', 'ᄋ', 'ᅴ', 'ᄀ', 'ᅧᆫ', '▁', 'ST', 'R', 'O', 'N', 'G', '▁B', 'U', 'Y', '▁', 'ᄋ', 'ᅲᄌ', 'ᅵ', ',', '▁', '목표주', 'ᄀ', 'ᅡ', '▁1', '46', ',', '0', '00', 'ᄋ', 'ᅯᆫ', 'ᄋ', 'ᅳ로', '▁', '상', 'ᄒ', 'ᅣᆼ', '▁', 'ᄒ', 'ᅡᆫ', 'ᄀ', 'ᅮᆨ', 'ᄒ', 'ᅡᆼ', 'ᄀ', 'ᅩᆼ', 'ᄋ', 'ᅮ주', '▁', '투자', 'ᄋ', 'ᅴ', 'ᄀ', 'ᅧᆫ', '▁', 'ST', 'R', 'O', 'N', 'G', '▁B', 'U', 'Y', '를', '▁', 'ᄋ', 'ᅲᄌ', 'ᅵ', 'ᄒ', 'ᅡ며', ',', '▁', '목표주', 'ᄀ', 'ᅡ는', '▁', 'ᄀ', 'ᅵ', '존', '▁11', '5,000', 'ᄋ', 'ᅯᆫ', 'ᄋ', 'ᅦ서', '▁27', '.', '0%', '▁', '상', 'ᄒ', 'ᅣᆼ', '▁', '조정', 'ᄒ', 'ᅡᆫ', '▁1', '46', ',', '0', '00', 'ᄋ', 'ᅯᆫ', 'ᄋ', 'ᅳ로', '▁', '수정', '▁', '제ᄉ', 'ᅵ', 'ᄒ', 'ᅡᆫ다', '.', '▁', '목표주', 'ᄀ', 'ᅡ', '▁', '상', 'ᄒ', 'ᅣᆼ', 'ᄀ', 'ᅳᆫ', 'ᄀ', 'ᅥ는', '▁R', 'O', 'E', '▁', '상', 'ᄒ', 'ᅣᆼ', '(', '21', '.', '2%', '\\uf0e0', '22', '.', '7%)', 'ᄋ', 'ᅦ', '▁', '따른', '▁', '적', 'ᄋ', 'ᅭᆼ', '▁', '밸류', 'ᄋ', 'ᅦ', 'ᄋ', 'ᅵ', '션', '▁', '상', 'ᄒ', 'ᅣᆼ', '(', 'P', 'B', 'R', '▁5', '.', '3', '▁-', '>', '▁6', '.', '8', '배', ')', 'ᄋ', 'ᅦ', '▁', 'ᄀ', 'ᅵ', 'ᄋ', 'ᅵ', 'ᆫ', 'ᄒ', 'ᅡᆫ다', '.', '▁2', 'Q', '16', '▁', 'ᄉ', 'ᅵ', 'ᆯ적', 'ᄋ', 'ᅳᆯ', '▁', '통', 'ᄒ', 'ᅢ', '▁', 'ᄋ', 'ᅧᆫ', 'ᄀ', 'ᅡᆫ', '▁', '두', '▁', '자ᄅ', 'ᅵ', '대', 'ᄋ', 'ᅴ', '▁', 'ᄋ', 'ᅧᆼ', 'ᄋ', 'ᅥᆸ', 'ᄋ', 'ᅵ', 'ᄋ', 'ᅵ', 'ᆨ률', 'ᄋ', 'ᅳᆯ', '▁', '충분', 'ᄒ', 'ᅵ', '▁', 'ᄀ', 'ᅵ', '록', 'ᄒ', 'ᅡᆯ', '▁', '수', '▁', 'ᄋ', 'ᅵ', 'ᆻ', 'ᄋ', 'ᅳᆷ', 'ᄋ', 'ᅵ', '▁', 'ᄒ', 'ᅪᆨ', 'ᄋ', 'ᅵ', 'ᆫ되', 'ᄋ', 'ᅥᆻ', 'ᄀ', 'ᅵ', '▁', '때문', 'ᄋ', 'ᅦ', '▁', 'ᄀ', 'ᅡ능', 'ᄒ', 'ᅡᆫ', '▁', '목표주', 'ᄀ', 'ᅡ', '▁', '상', 'ᄒ', 'ᅣᆼ', 'ᄋ', 'ᅵ', '다', '.', '▁2011', '년', '▁', '상장', '▁', 'ᄋ', 'ᅵ', 'ᄒ', 'ᅮ', '▁', '짝수년도', 'ᄋ', 'ᅴ', '▁', 'ᄉ', 'ᅵ', 'ᆫ', 'ᄀ', 'ᅲ수주는', '▁', 'ᄒ', 'ᅩᆯ수년도', '▁', '대ᄇ', 'ᅵ', '▁', '부ᄌ', 'ᅵ', 'ᆫ', 'ᄒ', 'ᅢᆻ다', '.', '▁', 'ᄒ', 'ᅧᆫ재는', '▁', 'ᄉ', 'ᅵ', 'ᆯ적', '▁', '증', 'ᄀ', 'ᅡ', 'ᄋ', 'ᅦ', '▁', 'ᄀ', 'ᅪᆫᄉ', 'ᅵ', 'ᆷ', 'ᄋ', 'ᅳᆯ', '▁', '둘', '▁', '때', 'ᄋ', 'ᅵ', 'ᆯ', '▁', '뿐', ',', '▁', '수주는', '▁2017', '년', '▁', '다ᄉ', 'ᅵ', '▁', 'ᄀ', 'ᅵ', '대', 'ᄒ', 'ᅡ는', '▁', 'ᄀ', 'ᅥᆺ', 'ᄋ', 'ᅵ', '▁', '타당', 'ᄒ', 'ᅡᆫ', '▁', 'ᄉ', 'ᅵ', '점', 'ᄋ', 'ᅵ', '다', '.', '▁', 'ᄒ', 'ᅧᆫ재주', 'ᄀ', 'ᅡ는', '▁2016', '년', '▁', 'ᄉ', 'ᅵ', 'ᆯ적추정ᄎ', 'ᅵ', '▁', 'ᄀ', 'ᅵ', '준', '▁P', 'ER', '▁29', '.', '0', '배', ',', '▁P', 'B', 'R', '▁5', '.', '6', '배다', '.']\n",
      "\n",
      "After Convert tokens to ids\n",
      "length: 396 \n",
      "[517, 0, 491, 0, 490, 0, 517, 350, 342, 329, 322, 290, 637, 356, 360, 517, 491, 0, 494, 46, 517, 0, 490, 0, 529, 168, 46, 60, 79, 491, 0, 491, 0, 517, 0, 493, 0, 517, 493, 0, 490, 0, 493, 0, 490, 0, 491, 0, 517, 0, 491, 0, 490, 0, 517, 350, 342, 329, 322, 290, 637, 356, 360, 0, 517, 491, 0, 494, 493, 0, 46, 517, 0, 490, 0, 517, 490, 494, 0, 538, 175, 491, 0, 491, 0, 585, 54, 61, 517, 0, 493, 0, 517, 0, 493, 0, 529, 168, 46, 60, 79, 491, 0, 491, 0, 517, 0, 517, 0, 494, 493, 0, 54, 517, 0, 490, 0, 517, 0, 493, 0, 490, 0, 490, 0, 686, 329, 282, 517, 0, 493, 0, 18, 133, 54, 120, 0, 134, 54, 204, 491, 0, 517, 0, 517, 0, 491, 0, 517, 0, 491, 0, 491, 494, 0, 517, 0, 493, 0, 18, 333, 270, 342, 611, 54, 142, 524, 257, 617, 54, 219, 0, 40, 491, 0, 517, 490, 494, 491, 494, 0, 493, 0, 54, 553, 341, 113, 517, 0, 494, 0, 491, 0, 517, 0, 493, 0, 517, 491, 0, 490, 0, 517, 0, 517, 0, 494, 0, 491, 0, 517, 491, 0, 491, 0, 491, 494, 491, 494, 0, 491, 0, 517, 0, 493, 494, 517, 490, 494, 0, 493, 0, 517, 0, 517, 491, 494, 0, 491, 0, 491, 494, 517, 493, 0, 491, 494, 0, 491, 0, 490, 494, 517, 0, 491, 0, 517, 490, 0, 493, 0, 517, 0, 490, 0, 517, 0, 493, 0, 491, 494, 0, 54, 568, 0, 517, 0, 517, 491, 494, 493, 0, 517, 0, 491, 0, 517, 0, 494, 0, 490, 0, 517, 493, 0, 517, 0, 494, 517, 0, 494, 0, 493, 0, 54, 517, 493, 0, 517, 0, 494, 0, 517, 0, 490, 0, 491, 0, 517, 490, 0, 494, 0, 491, 0, 517, 0, 517, 0, 491, 494, 0, 517, 0, 46, 517, 0, 578, 0, 517, 0, 494, 517, 490, 494, 0, 493, 0, 517, 490, 0, 491, 494, 517, 0, 493, 0, 517, 0, 494, 0, 491, 494, 0, 54, 517, 493, 0, 490, 0, 577, 0, 517, 0, 494, 0, 494, 517, 490, 494, 0, 681, 283, 587, 54, 60, 0, 46, 681, 270, 342, 611, 54, 188, 0, 54]\n",
      "\n",
      "After convert torch.tensor\n",
      "length: 1 \n",
      "tensor([[517,   0, 491,   0, 490,   0, 517, 350, 342, 329, 322, 290, 637, 356,\n",
      "         360, 517, 491,   0, 494,  46, 517,   0, 490,   0, 529, 168,  46,  60,\n",
      "          79, 491,   0, 491,   0, 517,   0, 493,   0, 517, 493,   0, 490,   0,\n",
      "         493,   0, 490,   0, 491,   0, 517,   0, 491,   0, 490,   0, 517, 350,\n",
      "         342, 329, 322, 290, 637, 356, 360,   0, 517, 491,   0, 494, 493,   0,\n",
      "          46, 517,   0, 490,   0, 517, 490, 494,   0, 538, 175, 491,   0, 491,\n",
      "           0, 585,  54,  61, 517,   0, 493,   0, 517,   0, 493,   0, 529, 168,\n",
      "          46,  60,  79, 491,   0, 491,   0, 517,   0, 517,   0, 494, 493,   0,\n",
      "          54, 517,   0, 490,   0, 517,   0, 493,   0, 490,   0, 490,   0, 686,\n",
      "         329, 282, 517,   0, 493,   0,  18, 133,  54, 120,   0, 134,  54, 204,\n",
      "         491,   0, 517,   0, 517,   0, 491,   0, 517,   0, 491,   0, 491, 494,\n",
      "           0, 517,   0, 493,   0,  18, 333, 270, 342, 611,  54, 142, 524, 257,\n",
      "         617,  54, 219,   0,  40, 491,   0, 517, 490, 494, 491, 494,   0, 493,\n",
      "           0,  54, 553, 341, 113, 517,   0, 494,   0, 491,   0, 517,   0, 493,\n",
      "           0, 517, 491,   0, 490,   0, 517,   0, 517,   0, 494,   0, 491,   0,\n",
      "         517, 491,   0, 491,   0, 491, 494, 491, 494,   0, 491,   0, 517,   0,\n",
      "         493, 494, 517, 490, 494,   0, 493,   0, 517,   0, 517, 491, 494,   0,\n",
      "         491,   0, 491, 494, 517, 493,   0, 491, 494,   0, 491,   0, 490, 494,\n",
      "         517,   0, 491,   0, 517, 490,   0, 493,   0, 517,   0, 490,   0, 517,\n",
      "           0, 493,   0, 491, 494,   0,  54, 568,   0, 517,   0, 517, 491, 494,\n",
      "         493,   0, 517,   0, 491,   0, 517,   0, 494,   0, 490,   0, 517, 493,\n",
      "           0, 517,   0, 494, 517,   0, 494,   0, 493,   0,  54, 517, 493,   0,\n",
      "         517,   0, 494,   0, 517,   0, 490,   0, 491,   0, 517, 490,   0, 494,\n",
      "           0, 491,   0, 517,   0, 517,   0, 491, 494,   0, 517,   0,  46, 517,\n",
      "           0, 578,   0, 517,   0, 494, 517, 490, 494,   0, 493,   0, 517, 490,\n",
      "           0, 491, 494, 517,   0, 493,   0, 517,   0, 494,   0, 491, 494,   0,\n",
      "          54, 517, 493,   0, 490,   0, 577,   0, 517,   0, 494,   0, 494, 517,\n",
      "         490, 494,   0, 681, 283, 587,  54,  60,   0,  46, 681, 270, 342, 611,\n",
      "          54, 188,   0,  54]])\n"
     ]
    }
   ],
   "source": [
    "sequence = df.iloc[2]['article']\n",
    "print(f\"length: {len(sequence)} \\n{sequence}\")\n",
    "print()\n",
    "\n",
    "print(\"After kobert_tokenize\")\n",
    "tokens = tokenizer.tokenize(sequence)\n",
    "print(f\"length: {len(tokens)} \\n{tokens}\"); print()\n",
    "\n",
    "print(\"After Convert tokens to ids\")\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(f\"length: {len(ids)} \\n{ids}\"); print()\n",
    "\n",
    "print(\"After convert torch.tensor\")\n",
    "input_ids = torch.tensor([ids])\n",
    "print(f\"length: {len(input_ids)} \\n{input_ids}\")\n",
    "\n",
    "# 위와 동일한 결과\n",
    "# tokenized_inputs = tokenizer(sequence, padding=True, max_length=512, truncation=True, return_tensors='pt')\n",
    "# print(tokenized_inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "20b1cd9a-2896-4ca2-945a-bea217e0bbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 396, 768])\n"
     ]
    }
   ],
   "source": [
    "output = model(input_ids)\n",
    "print(output['last_hidden_state'].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
