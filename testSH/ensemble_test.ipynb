{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e137c8ee-5c00-4c86-83d5-86b6b6121865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 11:38:42.609337: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoModel, AutoTokenizer, DataCollatorWithPadding\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from datasets import load_dataset\n",
    "from transformers import DataCollatorWithPadding\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06b39722-5cc8-4fe2-ba7f-d0bc081e1ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name_list = [\n",
    "    \"kbalbert_agument_epoch1_fold5_without_papago.pt\",\n",
    "    \"kbalbert_agument_epoch3_fold5_without_papago.pt\",\n",
    "    \"kbalbert_agument_epoch5_fold5_without_papago.pt\",\n",
    "    \"kbalbert_origin_epoch1_fold5.pt\",\n",
    "    \"kbalbert_origin_epoch3_fold5.pt\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42bd8ad3-f5a9-40e2-b892-4f1ff4fc69ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./models/kb-albert-char-base-v2 were not used when initializing AlbertModel: ['predictions.decoder.weight', 'predictions.LayerNorm.weight', 'predictions.decoder.bias', 'sop_classifier.classifier.bias', 'predictions.bias', 'sop_classifier.classifier.weight', 'predictions.dense.bias', 'predictions.dense.weight', 'predictions.LayerNorm.bias']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "kb_albert_model_path = \"./models/kb-albert-char-base-v2\"\n",
    "albert = AutoModel.from_pretrained(kb_albert_model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(kb_albert_model_path)\n",
    "\n",
    "tokenizer.truncation_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3942cdad-3364-4a04-a223-c5e3a8b61c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(0.25)\n",
    "        self.out_proj = torch.nn.Linear(768, 2)\n",
    "    \n",
    "    def forward(self, features):\n",
    "        # 보통 분류기에선 start 토큰에 분류 결과를 담음\n",
    "        x = features[:, 0, :]    # take <s> token (equiv. to [CLS])\n",
    "        x = x.reshape(-1, x.size(-1))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.out_proj(x)\n",
    "        return x\n",
    "\n",
    "class AInalyst(torch.nn.Module):\n",
    "    def __init__(self, pretrained_model):\n",
    "        super(AInalyst, self).__init__()\n",
    "        self.pretrained = pretrained_model\n",
    "        self.classifier = ClassificationHead()\n",
    "    \n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None):\n",
    "        outputs = self.pretrained(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            # labels=labels\n",
    "        )\n",
    "        self.labels = labels\n",
    "        logits = self.classifier(outputs[\"last_hidden_state\"])\n",
    "        # prob = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        \n",
    "        if labels is not None:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits, labels)\n",
    "            return logits, loss\n",
    "        else:\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bc34320-d388-4502-aec5-dde461ad6fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "load_model_list = list()\n",
    "\n",
    "for model_name in model_name_list:\n",
    "    load_model = copy.deepcopy(AInalyst(pretrained_model=albert))\n",
    "    load_model = torch.nn.DataParallel(load_model)\n",
    "    load_model.to(device)\n",
    "    \n",
    "    now_state = torch.load(f\"./models/{model_name}\")    \n",
    "    load_model.load_state_dict(now_state)\n",
    "    load_model.eval()\n",
    "    \n",
    "    load_model_list.append(load_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8d4916b-1954-405d-8e11-e86cf8d7e4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-68bfb0a5382dece9\n",
      "Reusing dataset csv (/home/piai/.cache/huggingface/datasets/csv/default-68bfb0a5382dece9/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4071e8460e7c472e91b07706ac7d4d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/piai/.cache/huggingface/datasets/csv/default-68bfb0a5382dece9/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-e1e08dbd646bbdf1.arrow\n"
     ]
    }
   ],
   "source": [
    "def inference_tokenized_fn(data):\n",
    "    outputs = tokenizer(data[\"article\"], padding=\"max_length\", max_length=MAX_LEN, truncation=True)\n",
    "    return outputs\n",
    "\n",
    "inference_dataset = load_dataset(\"csv\", data_files=f\"./data/inference_data.csv\")[\"train\"]\n",
    "inference_dataset = inference_dataset.map(inference_tokenized_fn,\n",
    "                                          remove_columns=[\"Unnamed: 0\", \"company\", \"title\", \"opinion\", \"firm\", \"date\", \"article\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b728ba0e-cf3f-4ee3-882a-34cf039582ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "inference_dataloader = torch.utils.data.DataLoader(\n",
    "    inference_dataset,\n",
    "    sampler = torch.utils.data.SequentialSampler(inference_dataset),\n",
    "    batch_size = 1,\n",
    "    collate_fn = data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfb36fd4-7a29-4d0e-b586-e1050a9b2857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38ebe7c0-1981-4784-85b8-6feeee7d6d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inference:   0%|                           | 10/50083 [00:01<1:57:30,  7.10it/s]\n"
     ]
    }
   ],
   "source": [
    "probabilities = [list() for _ in model_name_list]\n",
    "predictions = [list() for _ in model_name_list]\n",
    "\n",
    "for step, batch in enumerate(tqdm(inference_dataloader, desc=\"inference\", mininterval=0.1)):\n",
    "    if step == 10:\n",
    "        break\n",
    "    \n",
    "    batch_input_ids = batch[\"input_ids\"].to(device)\n",
    "    batch_attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "    for idx, load_model in enumerate(load_model_list):\n",
    "        with torch.no_grad():\n",
    "            logits = load_model(\n",
    "                input_ids = batch_input_ids,\n",
    "                attention_mask = batch_attention_mask,\n",
    "            )\n",
    "\n",
    "            prob = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            predict = torch.argmax(prob, axis=1)\n",
    "            \n",
    "            if predict == 1:\n",
    "                prob = np.round(np.max(prob.detach().cpu().numpy(), axis=1) * 100, 2)\n",
    "            else:\n",
    "                prob = np.round((1 - np.max(prob.detach().cpu().numpy(), axis=1)) * 100, 2)\n",
    "                \n",
    "            predict = predict.detach().cpu().numpy()\n",
    "\n",
    "            probabilities[idx].append(prob[0])\n",
    "            predictions[idx].append(predict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fd5aa827-c55a-4811-9d95-042fa6e66dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99.92599945 78.8320003  24.11800039 57.68200111  0.47        2.584\n",
      "  0.354      68.70800133 99.88599854 15.72799962]\n",
      "[1 1 0 1 0 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "ensemble_prob = np.mean(probabilities, axis=0, dtype=np.float64)\n",
    "ensemble_pred = (ensemble_prob > 50).astype(np.int32)\n",
    "\n",
    "inference_dataframe = pd.read_csv(\"./data/inference_data.csv\")\n",
    "\n",
    "convert_pred = list(map(lambda x: \"매수\" if x == 1 else \"매도\", ensemble_pred))\n",
    "convert_prob = list(map(lambda x: np.round(x, 2) if x > 50 else np.round(100 - x, 2), ensemble_prob))\n",
    "\n",
    "inference_dataframe = inference_dataframe.drop(labels=\"Unnamed: 0\", axis=1)\n",
    "inference_dataframe[\"predictions\"] = convert_pred\n",
    "inference_dataframe[\"pred_rate\"] = convert_prob\n",
    "inference_dataframe.to_csv(f\"./data/ensemble_inference_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "87fcb6aa-edfe-4cd0-a232-d84a54317197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models prob\n",
      "[[99.82, 97.59, 59.58, 30.53, 0.4, 1.75, 0.89, 42.4, 99.77, 3.41], [99.99, 1.01, 0.09, 99.86, 0.01, 0.13, 0.01, 99.97, 99.99, 0.03], [99.98, 99.98, 0.06, 99.91, 0.03, 0.05, 0.04, 2.08, 99.99, 70.92], [99.89, 95.97, 3.52, 13.52, 0.28, 0.53, 0.6, 99.16, 99.74, 1.93], [99.95, 99.61, 57.34, 44.59, 1.63, 10.46, 0.23, 99.93, 99.94, 2.35]]\n",
      "================================================================================\n",
      "models pred\n",
      "[[1, 1, 1, 0, 0, 0, 0, 0, 1, 0], [1, 0, 0, 1, 0, 0, 0, 1, 1, 0], [1, 1, 0, 1, 0, 0, 0, 0, 1, 1], [1, 1, 0, 0, 0, 0, 0, 1, 1, 0], [1, 1, 1, 0, 0, 0, 0, 1, 1, 0]]\n",
      "================================================================================\n",
      "ensemble\n",
      "[99.93, 78.83, 75.88, 57.68, 99.53, 97.42, 99.65, 68.71, 99.89, 84.27]\n",
      "['매수', '매수', '매도', '매수', '매도', '매도', '매도', '매수', '매수', '매도']\n"
     ]
    }
   ],
   "source": [
    "print(\"models prob\")\n",
    "print(probabilities)\n",
    "print(\"=\" * 80)\n",
    "print(\"models pred\")\n",
    "print(predictions)\n",
    "print(\"=\" * 80)\n",
    "print(\"ensemble\")\n",
    "print(convert_prob)\n",
    "print(convert_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e92f700-47cf-47e2-8694-c9d7f04781d2",
   "metadata": {},
   "source": [
    "## Test output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d90e0c4c-f37e-4e34-85e9-6804c517d216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "매수 99.93\n",
      "\n",
      "\n",
      "투자의견 BUY, 목표주가 480,000원 유지!동사의 투자의견 매수와 목표주가 를 유지한다. 상반기 스마트폰 시장 침체 에도 동사의 실적은 견조했다. 1) 하반기 북미 고객사의 신모델 출시가 기대되는 상황이며 , 2) 동사는 차질없이 물량을 공급하고 있는 것으로 파악된다. 3) 즉 , 하반기 실적 가시성은 확보 되었다. 전방 시장의 불확실성 에도 동사는 안전한 투자처가 될 것으로 판단된다 . 22년 역대 최대 실적을 기록할 전망이며 현재 12MF EPS 기준 PER 7.4배다. 여전히 주가 매력도 가 높고 실적 대비 저평가 구간이다 . 따라서 조정은 위기가 아닌 매수기회다.\n",
      "\n",
      "====================================================================================================\n",
      "매수 78.83\n",
      "\n",
      "\n",
      "투자의견 BUY, 목표주가 220,000원 유지동사의 투자의견 매수와 목표주가 를 유지 한다. 1) 패키지 기판 수요 는 여전히 타이트한 상황이며 3 분기에도 현 기조 를 유지할 전망이다. 2) MLCC 재고조정은 3 분기까지 지속되나 이는 MLCC 재고수준을 정상화하는 기간으로 판단된다. 2 분기는 MLCC 사이클 저점에서 동사의 기초체력을 재평가는 시기였다. 불확실한 수요가 지속되는 가운데 실적 비수기인 상반기가 지났다 . 하반기 는 IT 성수기 이므로 기저효과 가 기대된다.\n",
      "\n",
      "====================================================================================================\n",
      "매도 75.88\n",
      "\n",
      "\n",
      "전망치 상향 조정으로 목표주가 53만원으로 상향LG에너지솔루션에 대한 투자의견 BUY 를 유지하고 목표주가는 기존 50 만원에서 53만원으로 상향한다. 적용된 멀티플은 18 배로 하향하나 판가 가격전가력 확대 /CAPA 상향 등으로 2024 년 EBITDA 추정치를 상향한 결과다. 2 분기 수익성은 중국 코로나 락다운 여파와 원가 판가 전가시점의 차이로 하락했으나 하반기 고객사향 출하 회복 , GM 향 물량 추가 , 스프레드 개선 등으로 매출액 수익성이 동반 개선될 전망이다.\n",
      "\n",
      "====================================================================================================\n",
      "매수 57.68\n",
      "\n",
      "\n",
      "2Q22 Review : 높아진 컨센서스 상회LG이노텍의 2분기 매출액 3조 7,026억원(YoY+57.2%, QoQ-31.0%), 영업이익 2,899억원(YoY+83.7%, QoQ-21.0%) 최근 높아진 컨센서스 영업이익(매출액 3조 2,783억원, 영업이익2,545억원)을 상회하는 호실적을 발표. 광학솔루션사업부는 우호적인 환율속에 고객사의 판매량 호조와 높은 고부가 제품 비중효과가 작용. 기판소재사 업부는 1Q22부진했던 디스플레이 제품군의 양호한 실적과 반도체 패키지 기판의 견조한 수요와 생산능력 확대 효과 반영. 전장부품사업부는 차량용 통신모듈 및 모터가 증가 했으나 원자재 가격상승영향으로 수익성 개선이 지연.\n",
      "\n",
      "====================================================================================================\n",
      "매도 99.53\n",
      "\n",
      "\n",
      "2Q22 Review : 매크로 환경에 따른 부진지난 7일 잠정실적에서 발표한 바와 같이 LG에너지솔루션의 2분기 매출액 5조 706억원(YoY-1.2%, QoQ+16.8%), 영업이익 1,956억원(YoY-73.0%, QoQ-24.4%)의 실적을 발표. 원통형 EV매출 증대 및 원재료 가격 상승에 대응한 메탈가격 연동 및 판매가격 확대에 따라 매출액은 증가. 고객사 중국 락다운으로 인한 단기적인 수요부진 영향이 주요하게 반영되었으며 글로벌 물류대란과 원가 상승분의 판가 적용시점 차이로 인한 영업이익은 부진.\n",
      "\n",
      "====================================================================================================\n",
      "매도 97.42\n",
      "\n",
      "\n",
      "2Q22 매출액 808억원(+26.9% YoY) 영업이익 247억원(+31.7% YoY)2Q22 매출액은 YoY 26.9% 성장한 808억원, 영업이익은 YoY 31.7% 성장한 247억원으로, 교보증권에서 추정한 매출액 및 영업이익 대비 각각 5.9%, 5.8% 하회. 이는 수요부진에 따른 가동률 하락이 원인은 아니며, 다만 일부 고객사의 재고조정 때문으로 파악. 중국 현지에 법인을 두고 있는 고객사가 중국 봉쇄로 인한 부품공급 지연을 염려하여 재고를 일정 수준 이상으로 쌓았기 때문이며, 중국 봉쇄 리스크가 완화된 6월부터 재고조정이 시작되었고 3분기까지 진행될 것으로 전망.\n",
      "\n",
      "====================================================================================================\n",
      "매도 99.65\n",
      "\n",
      "\n",
      "목표주가 52,000원 → 40,000원으로 23.1% 하향. 실적 추정치 하향GS건설에 대해 투자의견 ‘매수’ 유지. 목표주가는 52,000원 → 40,000원으로 23.1% 하향. 목표주가 하향은 2분기 연속 실적 추정치 하회, 상반기 실적 하향 요인인 원자재 가격 상승•노무비 증가 등 원가 상승 영향 하반기 지속에 따른 연간 추정치 하향에 따름. 2Q22 실적은 이라크 까르발라 일회성 손실 반영으로 시장 기대치 하회 불구, 양호한 수준으로 판단. 상반기 신규수주는 7.8조원으로 연초 계획 대비 53% 달성하며 양호한 수준. 하지만 수주잔고의 대부분이 건축•주택부문에 치중 되어, 최근 급격한 금리 인상에 따른 주택 시황 변화와 원자재•노무비 상승 등의 비용 부담 증가가 주택 비중이 높은 동사의 안정적인 지속 성장에 위협 요소로 판단. 신사업 등 수주 다각화 노력이 지속되고 있지만, 전통적인 해외 시장에서의 신규수주 확대가 필요한 시점으로 판단.\n",
      "\n",
      "====================================================================================================\n",
      "매수 68.71\n",
      "\n",
      "\n",
      "투자의견 ‘매수’ 및 목표주가 150,000원 유지. 최대 실적 다시 경신삼성물산에 대해 투자의견 ‘매수’ 및 목표주가 150,000원 유지. 2Q22 실적은 글로벌 원자재 가격 상승•공급망 훼손 등 경영환경 악화 불구, 경영체질 개선 및 사업 경쟁력 강화 노력에 힘입어 외형과 수익성 모두 크게 개선, 역대 최대 영업이익 경신. 2분기 연속 실적 서프라이즈로 목표주가 상향요인 있으나, 여전한 목표 주가 괴리율과 최근 글로벌 경기 침체 우려에 따른 자회사 지분 가치 하락 리스크를 감안 목표주가 유지. ① 1H22 건설부문 신규 수주는 계열사 신규 투자, 베트남 복합 발전 등 8.6조원으로 연간목표 11조원 대비 73.5% 달성. ② 매출화 빠른 하이테크 공사 진행률 증가, 상사를 포함한 사업 전부문 안정적 이익 체력 구축으로 합병 이후 최초로 연간 영업이익 2조원 달성 전망. 매수 추천.\n",
      "\n",
      "====================================================================================================\n",
      "매수 99.89\n",
      "\n",
      "\n",
      "새로운 해결사 등장. VSIG4 표적의 EU103유틸렉스는 면역항암제 전문 기업이다. 주력 파이프라인 EU103은 VSIG4를 표적하는 항체치료제로 면역을 억제하는 M2 대식세포를 면역을 유도하는 M1 대식세포로 전환하고 동시에 T세포 억제를 막는 것이 핵심 기전이다. 그리고 EU103은 종양항원이 표적이 아니라 면역세포를 표적하기 때문에 다양한 고형암으로 적응증을 확대하기 용이하다. 특히 유틸렉스는 VSIG4에 대한 관심이 크지 않던 2016년부터 관련 논문을 발간하며 연구해왔다는 점이 특징이다. 그런데 최근 Pubmed나 Google Scholar에서 급증하는 논문 검색 수를 고려할 때 VSIG4에 대한 학계의 관심은 굉장히 빠르게 높아짐을 알 수 있다. 더구나 유틸렉스는 최근 바이오 USA 등에서 글로벌 제약사와 기술이전을 논의하고 있다고 언론에 보도된 바 있다. 교보증권은 항-VSIG4 항체로 면역을 활성화하는 기전에 대한 업계의 뜨거운 관심을 고려해 EU103은 비임상 단계에서도 높은 가치를 인정받고 기술이전이 가능하다고 판단한다.\n",
      "\n",
      "====================================================================================================\n",
      "매도 84.27\n",
      "\n",
      "\n",
      "2Q22 실적 Review연결 매출 6,514억(QoQ +27.4%, YoY +58.0%), OP 1,697억(QoQ -3.8%, YoY +1.7%) 기록. 2Q22 실적에는 이전까지 지분법으로 반영되던 에피스 실적이 연결로 반영되어 QoQ, YoY 단순 비교 어려워 별도 매출 5,037억, OP 1,719억 기록. 2공장 정기유지보수 영향으로 가동률 소폭 하락하였으나 환율 및 3공장 판매량 증가하며 호실적 기록 에피스 매출 2,328억, OP 585억 기록. 다만 이번 연결 실적에는 5월-6월분인 매출 1,494억 OP 300억 반영\n",
      "\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for idx, (_, element) in enumerate(inference_dataframe.iterrows()):\n",
    "    if idx == 30:\n",
    "        break\n",
    "    print(element[\"predictions\"], element[\"pred_rate\"])\n",
    "    print(element[\"article\"])\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf78b170-5881-40e7-9e64-e1d3585f1ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
