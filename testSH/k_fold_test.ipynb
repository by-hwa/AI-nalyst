{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "960fc129-40a9-4e77-9ffc-66d48fa09ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 17:36:43.473002: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoModel, AutoTokenizer, DataCollatorWithPadding\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from datasets import load_dataset\n",
    "from transformers import DataCollatorWithPadding\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed9824c9-6abf-4f13-b6f7-298e95351978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal data load\n",
    "strongbuy = pd.read_csv(\"./data/strongbuy.csv\")\n",
    "sell = pd.read_csv(\"./data/sell.csv\")\n",
    "holddown = pd.read_csv(\"./data/holddown.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5a8af10-1f8a-4823-8051-cd3e49524d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand eata load\n",
    "strongbuy_expand_google_en = pd.read_csv(\"./data/strongbuy_expand_google_en.csv\")\n",
    "strongbuy_expand_google_zhcn = pd.read_csv(\"./data/strongbuy_expand_google_zhcn.csv\")\n",
    "strongbuy_expand_pororo_en = pd.read_csv(\"./data/strongbuy_expand_pororo_en.csv\")\n",
    "\n",
    "sell_expand_google_en = pd.read_csv(\"./data/sell_expand_google_en.csv\")\n",
    "sell_expand_google_zhcn = pd.read_csv(\"./data/sell_expand_google_zhcn.csv\")\n",
    "sell_expand_pororo_en = pd.read_csv(\"./data/sell_expand_pororo_en.csv\")\n",
    "\n",
    "holddown_expand_google_en = pd.read_csv(\"./data/holddown_expand_google_en.csv\")\n",
    "holddown_expand_google_zhcn = pd.read_csv(\"./data/holddown_expand_google_zhcn.csv\")\n",
    "holddown_expand_pororo_en = pd.read_csv(\"./data/holddown_expand_pororo_en.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77ec7bb6-29c9-4596-bfc9-8fee5e0fe9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>article</th>\n",
       "      <th>length</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>strongbuy65.txt</td>\n",
       "      <td>상승, 2Q15의 주가 : KRW 365.3 억 유로의 매출, 421 억 유로 (O...</td>\n",
       "      <td>382</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>strongbuy234.txt</td>\n",
       "      <td>2021년 배터리 소재인데, 아직도 PER 7배? 2020년 위기에도 강한 실적 복...</td>\n",
       "      <td>362</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>strongbuy44.txt</td>\n",
       "      <td>6년 만에 처음으로 소송을 마무리하면서 29억 달러를 배포하고, 2009년부터 시작...</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>holddown126.txt</td>\n",
       "      <td>1Q는 약간 낮습니다.좋은 외모 성장.170 만 원의 낮은 이익 마진 중에 회사는 ...</td>\n",
       "      <td>429</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>302.txt</td>\n",
       "      <td>이 회사는 4 분기에 상당한 선제 명령을 받았으며 장기 헌장 선박의 평균 비용은 현...</td>\n",
       "      <td>347</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>보유하향57.txt</td>\n",
       "      <td>2분기 대형 손실회사는 1조6,94억원의 순손실, 영업손실 17억4,000억원, 순...</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>holddown113.txt</td>\n",
       "      <td>3Q21 Review: 특이사항 없음 3Q21 매출액 606억원(YoY +13%),...</td>\n",
       "      <td>728</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>strongbuy432.txt</td>\n",
       "      <td>렌터카 업체 대부분이 EV,EBITDA 기준으로 5배 이상 평가받는 이유는 핵심 자...</td>\n",
       "      <td>404</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10998</th>\n",
       "      <td>strongbuy410.txt</td>\n",
       "      <td>투자 의견은 강력하게 구입하고 목표 가격은 25,000 원, 목표 가격은 25,00...</td>\n",
       "      <td>340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>se11_content48.txt</td>\n",
       "      <td>2분기 영업적자가 2,431억원에 달할 것으로 예상되는 가운데 적자 확대액은 한국의...</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 filename                                            article  \\\n",
       "0         strongbuy65.txt  상승, 2Q15의 주가 : KRW 365.3 억 유로의 매출, 421 억 유로 (O...   \n",
       "1        strongbuy234.txt  2021년 배터리 소재인데, 아직도 PER 7배? 2020년 위기에도 강한 실적 복...   \n",
       "2         strongbuy44.txt  6년 만에 처음으로 소송을 마무리하면서 29억 달러를 배포하고, 2009년부터 시작...   \n",
       "3         holddown126.txt  1Q는 약간 낮습니다.좋은 외모 성장.170 만 원의 낮은 이익 마진 중에 회사는 ...   \n",
       "4                 302.txt  이 회사는 4 분기에 상당한 선제 명령을 받았으며 장기 헌장 선박의 평균 비용은 현...   \n",
       "...                   ...                                                ...   \n",
       "10995          보유하향57.txt  2분기 대형 손실회사는 1조6,94억원의 순손실, 영업손실 17억4,000억원, 순...   \n",
       "10996     holddown113.txt  3Q21 Review: 특이사항 없음 3Q21 매출액 606억원(YoY +13%),...   \n",
       "10997    strongbuy432.txt  렌터카 업체 대부분이 EV,EBITDA 기준으로 5배 이상 평가받는 이유는 핵심 자...   \n",
       "10998    strongbuy410.txt  투자 의견은 강력하게 구입하고 목표 가격은 25,000 원, 목표 가격은 25,00...   \n",
       "10999  se11_content48.txt  2분기 영업적자가 2,431억원에 달할 것으로 예상되는 가운데 적자 확대액은 한국의...   \n",
       "\n",
       "       length  label  \n",
       "0         382      1  \n",
       "1         362      1  \n",
       "2         199      1  \n",
       "3         429      0  \n",
       "4         347      0  \n",
       "...       ...    ...  \n",
       "10995     218      0  \n",
       "10996     728      0  \n",
       "10997     404      1  \n",
       "10998     340      1  \n",
       "10999     415      0  \n",
       "\n",
       "[11000 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all_data = pd.concat([strongbuy, sell, holddown])\n",
    "\n",
    "all_data = pd.concat([strongbuy, strongbuy_expand_google_en, strongbuy_expand_google_zhcn, strongbuy_expand_pororo_en,\n",
    "                      sell, sell_expand_google_en, sell_expand_google_zhcn, sell_expand_pororo_en,\n",
    "                      holddown, holddown_expand_google_en, holddown_expand_google_zhcn, holddown_expand_pororo_en])\n",
    "all_data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aecb10bc-3cb6-4517-923a-c62a8ec3bdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 : 0.6799\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(strongbuy)/len(strongbuy)} : {(len(sell) + len(holddown)) / len(strongbuy):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6a91312-4e94-4945-a3d2-4390721820b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(all_data, test_size=0.2, random_state=42, stratify=all_data[[\"label\"]])\n",
    "\n",
    "test_data[\"labels\"] = test_data[\"label\"]\n",
    "test_data = test_data.drop(labels=[\"filename\", \"length\", \"label\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2cb32b5-ba67-4b47-9dd0-7bcfc052630d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_length = 5\n",
    "X = train_data.drop(labels=[\"filename\", \"length\", \"label\"], axis=1)\n",
    "y = train_data[\"label\"]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=fold_length, shuffle=True, random_state=42)\n",
    "fold_dataframe = list()\n",
    "\n",
    "for fold_number, (train, valid) in enumerate(skf.split(X, y), 1):\n",
    "    X_train, X_valid = X.iloc[train], X.iloc[valid]\n",
    "    y_train, y_valid = y.iloc[train], y.iloc[valid]\n",
    "    \n",
    "    fold_train = X_train.loc[:]\n",
    "    fold_train[\"labels\"] = y_train\n",
    "    \n",
    "    fold_valid = X_valid.loc[:]\n",
    "    fold_valid[\"labels\"] = y_valid\n",
    "    \n",
    "    fold_train.to_csv(f\"./data/train_data_fold{fold_number}.csv\", index=False)\n",
    "    fold_valid.to_csv(f\"./data/valid_data_fold{fold_number}.csv\", index=False)\n",
    "\n",
    "test_data.to_csv(f\"./data/test_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80934118-b730-40a7-a091-25b34c4698fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./models/kb-albert-char-base-v2 were not used when initializing AlbertModel: ['predictions.dense.weight', 'sop_classifier.classifier.weight', 'predictions.LayerNorm.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'sop_classifier.classifier.bias', 'predictions.bias', 'predictions.LayerNorm.weight', 'predictions.dense.bias']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "kb_albert_model_path = \"./models/kb-albert-char-base-v2\"\n",
    "albert = AutoModel.from_pretrained(kb_albert_model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(kb_albert_model_path)\n",
    "\n",
    "tokenizer.truncation_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da9885a5-7c0f-4ba9-a4ac-27439beed01f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-fdc6debd7b5f9adb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-fdc6debd7b5f9adb/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243c43b8e8ba4c859bcd1522a6612da4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d943773f31684501acc618a791f1ed34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-fdc6debd7b5f9adb/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4773129dae84ec3adda4856d8599c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-2de449cdcd272d92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-2de449cdcd272d92/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b17feef766b844f5a85c4060ee6d77dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ebfcd955d5340ef95b5343dd9c09b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-2de449cdcd272d92/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b35b04f6d16d4c2782a2492317c55d9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e317eecea14b7b890af84b80b98df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7040 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864ae08dffa24099a0653ae111363caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1760 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-ec0754f03e0c9f9e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-ec0754f03e0c9f9e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a071f6a16848a28beffda6667d30dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af75433d2d6c4f0cb6883e70fecb82f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-ec0754f03e0c9f9e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "030843c88901469098eebdf94dba2628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-d9179eb504127ae8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-d9179eb504127ae8/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7e8551238c432d94f8672742d8f397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792742787fad4132a86955ab219156fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-d9179eb504127ae8/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f62b471c11f641198a58a43401e80715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c4e5ed3603e4dcda55d1e544efb9e45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7040 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e13cc9bda343b7af155756aa4657d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1760 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-0f3ff9c690ca1eab\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-0f3ff9c690ca1eab/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1946597a971641c695fea94adecfc5d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bcd2a5e07b8486e911bc1658fbb61d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-0f3ff9c690ca1eab/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac7888d11834f80899ba5d2a4f9eb30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-c1f87acf2f374cdc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-c1f87acf2f374cdc/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d01241717f404daca9ee65d9ad1affeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9e098d0c60460c97d93d8abee938ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-c1f87acf2f374cdc/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f758520cf64755809fac4fc9fee94d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d013b8d42e64d0aaa88b7a25e2ccf21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7040 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38611b681788481bb48f672892b0a2c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1760 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-92015d5eb36925a2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-92015d5eb36925a2/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bd4a89bb8644d59830d179cffc66bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "791c1d03c5084c1eb28705686672c367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-92015d5eb36925a2/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5018811cc70343f5ac4b0cbc35028db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-cd94f5aeae548ad8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-cd94f5aeae548ad8/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f6ff5c8d104b83b71d2afc50aaaeca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd56db66c9d47c6b188c0879ee9b888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-cd94f5aeae548ad8/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cab1aadbbca4e8d9661296c6e766070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb3a6a566b8d4ef581064c00b30f4c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7040 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ac09840a264affac9515520a6c70fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1760 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-4a04d4856deb042f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-4a04d4856deb042f/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a896dc2f3675408b962dbc549bec6305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e5b4f8073c94df489502a39f7240fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-4a04d4856deb042f/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c99d851860144f03bc25d4c5222dc84d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-9ba365238ea8e24d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-9ba365238ea8e24d/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aae43e7d1494a6db2d94445e5579d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3dc12f2506f4c1197ae1e92779b2d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-9ba365238ea8e24d/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d11d7609064a32980490e82b10a448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3498e4978b2490abfcd1980f143da55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7040 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed540c651b1435aa399091c00bb5588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1760 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-2aba08cc8e91b411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-2aba08cc8e91b411/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb36ed26c56456794e30aea0c4244ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de7eb606480f4b5ea88b8b769fbc4f3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-2aba08cc8e91b411/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad84d401b05c49e9aa8d3397edad66f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929a9a4f2caf40098e7f9bba22038cb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2200 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LEN = 512\n",
    "\n",
    "def tokenized_fn(data):\n",
    "    outputs = tokenizer(data[\"article\"], padding=\"max_length\", max_length=MAX_LEN, truncation=True)\n",
    "    outputs[\"labels\"] = data[\"labels\"]\n",
    "    return outputs\n",
    "\n",
    "dataset_list = list()\n",
    "for fold_number in range(1, fold_length+1):\n",
    "    train_dataset = load_dataset(\"csv\", data_files=f\"./data/train_data_fold{fold_number}.csv\")[\"train\"]\n",
    "    valid_dataset = load_dataset(\"csv\", data_files=f\"./data/valid_data_fold{fold_number}.csv\")[\"train\"]\n",
    "\n",
    "    train_dataset = train_dataset.map(tokenized_fn, remove_columns=[\"article\"])\n",
    "    valid_dataset = valid_dataset.map(tokenized_fn, remove_columns=[\"article\"])\n",
    "    \n",
    "    dataset_list.append([train_dataset, valid_dataset])\n",
    "\n",
    "test_dataset = load_dataset(\"csv\", data_files=f\"./data/test_data.csv\")[\"train\"]\n",
    "test_dataset = test_dataset.map(tokenized_fn, remove_columns=[\"article\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15ac9d0d-6d71-4abb-89cc-5edede64a91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "dataloader_list = list()\n",
    "for train_fold, valid_fold in dataset_list:\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_fold,\n",
    "        sampler = torch.utils.data.RandomSampler(train_fold),\n",
    "        batch_size = batch_size,\n",
    "        collate_fn = data_collator,\n",
    "    )\n",
    "\n",
    "    validation_dataloader = torch.utils.data.DataLoader(\n",
    "        valid_fold,\n",
    "        sampler = torch.utils.data.SequentialSampler(valid_fold),\n",
    "        batch_size = batch_size,\n",
    "        collate_fn = data_collator,\n",
    "    )\n",
    "    \n",
    "    dataloader_list.append([train_dataloader, validation_dataloader])\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    sampler = torch.utils.data.SequentialSampler(test_dataset),\n",
    "    batch_size = batch_size,\n",
    "    collate_fn = data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96f5859f-689a-46a7-b2a0-7e583ef676b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(0.25)\n",
    "        self.out_proj = torch.nn.Linear(768, 2)\n",
    "    \n",
    "    def forward(self, features):\n",
    "        # 보통 분류기에선 start 토큰에 분류 결과를 담음\n",
    "        x = features[:, 0, :]    # take <s> token (equiv. to [CLS])\n",
    "        x = x.reshape(-1, x.size(-1))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.out_proj(x)\n",
    "        return x\n",
    "\n",
    "class AInalyst(torch.nn.Module):\n",
    "    def __init__(self, pretrained_model):\n",
    "        super(AInalyst, self).__init__()\n",
    "        self.pretrained = pretrained_model\n",
    "        self.classifier = ClassificationHead()\n",
    "    \n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None):\n",
    "        outputs = self.pretrained(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            # labels=labels\n",
    "        )\n",
    "        self.labels = labels\n",
    "        logits = self.classifier(outputs[\"last_hidden_state\"])\n",
    "        # prob = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        \n",
    "        if labels is not None:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits, labels)\n",
    "            return logits, loss\n",
    "        else:\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95223fe8-8c47-4d7f-8107-8231fe60127e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bf1f4ce-9a10-492a-b6cc-2736d78e669a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = AInalyst(pretrained_model=albert)\n",
    "model.to(device)\n",
    "model = torch.nn.DataParallel(model)\n",
    "isParallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a8a5431-14ec-4895-b3eb-58ba0e6d08ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0582000-da1b-4227-8aba-5eba428bab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05969563-c25e-4f37-8a30-90557db0f0cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ Epoch 1/1 ============\n",
      "Training...\n",
      "===== Epoch 1/1 - Fold 1/5 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piai/anaconda3/envs/iml/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Average training loss: 0.41387\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 0.90170\n",
      "===== Epoch 1/1 - Fold 2/5 =====\n",
      "\n",
      " Average training loss: 0.16961\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 0.94091\n",
      "===== Epoch 1/1 - Fold 3/5 =====\n",
      "\n",
      " Average training loss: 0.08203\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 0.98750\n",
      "===== Epoch 1/1 - Fold 4/5 =====\n",
      "\n",
      " Average training loss: 0.03474\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 0.99659\n",
      "===== Epoch 1/1 - Fold 5/5 =====\n",
      "\n",
      " Average training loss: 0.02120\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 0.99545\n",
      "===== Epoch 1/1 - Test =====\n",
      "\n",
      "Running Test...\n",
      "\n",
      " Test Accuracy: 0.94973\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    print(f\"============ Epoch {epoch+1}/{epochs} ============\")\n",
    "    print(\"Training...\")\n",
    "    \n",
    "    for fold_number, (train_dataloader, validation_dataloader) in enumerate(dataloader_list, 1):\n",
    "        print(f\"===== Epoch {epoch+1}/{epochs} - Fold {fold_number}/{fold_length} =====\")\n",
    "        total_train_loss = 0\n",
    "        model.train()\n",
    "\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            batch_input_ids = batch[\"input_ids\"].to(device)\n",
    "            batch_attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            batch_labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            model.zero_grad()\n",
    "\n",
    "            logits, loss = model(\n",
    "                input_ids = batch_input_ids,\n",
    "                attention_mask = batch_attention_mask,\n",
    "                labels = batch_labels,\n",
    "            )\n",
    "\n",
    "            if isParallel:\n",
    "                loss = loss.mean()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # if step % 1000 == 0 and not step == 0:\n",
    "            #     print(\"step : {:>5,} of {:>5,} loss: {:.5f}\".format(step, len(train_dataloader), loss.item()))\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "        print()\n",
    "        print(\" Average training loss: {0:.5f}\".format(avg_train_loss))\n",
    "\n",
    "        # Validation\n",
    "        print()\n",
    "        print(\"Running Validation...\")\n",
    "\n",
    "        model.eval()\n",
    "        total_eval_accuracy = 0\n",
    "        total_eval_loss = 0\n",
    "        nb_eval_steps = 0\n",
    "\n",
    "        for step, batch in enumerate(validation_dataloader):\n",
    "            batch_input_ids = batch[\"input_ids\"].to(device)\n",
    "            batch_attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            batch_labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits, loss = model(\n",
    "                    input_ids = batch_input_ids,\n",
    "                    attention_mask = batch_attention_mask,\n",
    "                    labels = batch_labels,\n",
    "                )\n",
    "\n",
    "                if isParallel:\n",
    "                    loss = loss.mean()\n",
    "\n",
    "                total_eval_loss += loss.item()\n",
    "                logits = logits.detach().cpu().numpy()\n",
    "                label_ids = batch_labels.to(\"cpu\").numpy()\n",
    "                total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "        avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "        print()\n",
    "        print(\" Valid Accuracy: {0:.5f}\".format(avg_val_accuracy))\n",
    "    \n",
    "    # Test\n",
    "    print(f\"===== Epoch {epoch+1}/{epochs} - Test =====\")\n",
    "    print()\n",
    "    print(\"Running Test...\")\n",
    "\n",
    "    model.eval()\n",
    "    total_test_accuracy = 0\n",
    "    total_test_loss = 0\n",
    "    nb_test_steps = 0\n",
    "    \n",
    "    for step, batch in enumerate(test_dataloader):\n",
    "        batch_input_ids = batch[\"input_ids\"].to(device)\n",
    "        batch_attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        batch_labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits, loss = model(\n",
    "                input_ids = batch_input_ids,\n",
    "                attention_mask = batch_attention_mask,\n",
    "                labels = batch_labels,\n",
    "            )\n",
    "\n",
    "            if isParallel:\n",
    "                loss = loss.mean()\n",
    "\n",
    "            total_test_loss += loss.item()\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = batch_labels.to(\"cpu\").numpy()\n",
    "            total_test_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "    avg_test_accuracy = total_test_accuracy / len(test_dataloader)\n",
    "    print()\n",
    "    print(\" Test Accuracy: {0:.5f}\".format(avg_test_accuracy))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06109df5-d5e7-421d-9012-04578ce923a5",
   "metadata": {},
   "source": [
    "## Model Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ba39b1e-c0a9-4510-9d55-8e42d5f11138",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./models/kbalbert_after_transfer_learning.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8dfe35-2c5f-41e8-bbb7-8ff2717ca604",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fec8ff9-0a6d-4d56-8d03-27f571a6da59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model = AInalyst(pretrained_model=albert)\n",
    "load_model.to(device)\n",
    "load_model = torch.nn.DataParallel(load_model)\n",
    "load_model.load_state_dict(torch.load(\"./models/kbalbert_after_transfer_learning.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60689f07-5a60-4029-875c-540b997341e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-68bfb0a5382dece9\n",
      "Reusing dataset csv (/home/piai/.cache/huggingface/datasets/csv/default-68bfb0a5382dece9/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2808fa8ab6db4eadb806d96eb05c717c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/piai/.cache/huggingface/datasets/csv/default-68bfb0a5382dece9/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-d946ad765fea21f9.arrow\n"
     ]
    }
   ],
   "source": [
    "def inference_tokenized_fn(data):\n",
    "    outputs = tokenizer(data[\"article\"], padding=\"max_length\", max_length=MAX_LEN, truncation=True)\n",
    "    return outputs\n",
    "\n",
    "inference_dataset = load_dataset(\"csv\", data_files=f\"./data/inference_data.csv\")[\"train\"]\n",
    "inference_dataset = inference_dataset.map(inference_tokenized_fn,\n",
    "                                          remove_columns=[\"Unnamed: 0\", \"company\", \"title\", \"opinion\", \"firm\", \"date\", \"article\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5dd4a261-c965-4c23-b541-100dcd01f2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_dataloader = torch.utils.data.DataLoader(\n",
    "    inference_dataset,\n",
    "    sampler = torch.utils.data.SequentialSampler(inference_dataset),\n",
    "    batch_size = 1,\n",
    "    collate_fn = data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5eaf7e1-56fc-4c9e-ac95-2d7dd36d21fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inference: 100%|██████████████████████████| 50083/50083 [19:41<00:00, 42.40it/s]\n"
     ]
    }
   ],
   "source": [
    "load_model.eval()\n",
    "\n",
    "probabilities = list()\n",
    "predictions = list()\n",
    "\n",
    "for step, batch in enumerate(tqdm(inference_dataloader, desc=\"inference\", mininterval=0.1)):\n",
    "    batch_input_ids = batch[\"input_ids\"].to(device)\n",
    "    batch_attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = load_model(\n",
    "            input_ids = batch_input_ids,\n",
    "            attention_mask = batch_attention_mask,\n",
    "        )\n",
    "        \n",
    "        prob = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        predict = torch.argmax(prob, axis=1)\n",
    "        \n",
    "        prob = np.round(np.max(prob.detach().cpu().numpy(), axis=1) * 100, 2)\n",
    "        predict = predict.detach().cpu().numpy()\n",
    "        \n",
    "        probabilities.append(prob[0])\n",
    "        predictions.append(predict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83876235-0f08-43ae-87eb-47af4e164747",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_dataframe = pd.read_csv(\"./data/inference_data.csv\")\n",
    "\n",
    "convert_predictions = list(map(lambda x: \"매수\" if x == 1 else \"매도\", predictions))\n",
    "inference_dataframe = inference_dataframe.drop(labels=\"Unnamed: 0\", axis=1)\n",
    "inference_dataframe[\"predictions\"] = convert_predictions\n",
    "inference_dataframe[\"pred_rate\"] = probabilities\n",
    "inference_dataframe.to_csv(f\"./data/convert_inference_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "803aa4a6-e9eb-4304-b7e1-ba8923c32777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "매수    37901\n",
       "매도    12182\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_dataframe[\"predictions\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7d9dad7-797b-4998-a41f-14b8418310d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_num = 0\n",
    "rl_num = 20\n",
    "\n",
    "# for arti, pred, pred_rate in zip(inference_dataframe[\"article\"][ll_num:rl_num], inference_dataframe[\"predictions\"][ll_num:rl_num], inference_dataframe[\"pred_rate\"][ll_num:rl_num]):\n",
    "#     print(pred, pred_rate)\n",
    "#     print(arti)\n",
    "#     print(\"=\" * 50)\n",
    "\n",
    "# for arti, pred, pred_rate in zip(inference_dataframe[\"article\"], inference_dataframe[\"predictions\"], inference_dataframe[\"pred_rate\"]):\n",
    "#     if pred_rate < 90:\n",
    "#         print(pred, pred_rate)\n",
    "#         print(arti)\n",
    "#         print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc901d8e-3916-497c-9a05-b6ec3247ee27",
   "metadata": {},
   "source": [
    "## Inference Data들 Merge해서 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0c90125-29ed-4946-a09b-fb4d8f6523cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/Inference_AllArgumentationData_5Epoch_5Fold.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17070/1612050000.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minf_origin_case1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/Inference_OnlyOrigindata_1Epoch_5Fold.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minf_origin_case2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/Inference_OnlyOrigindata_5Epoch_5Fold.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0minf_agument_case1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/Inference_AllArgumentationData_5Epoch_5Fold.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/iml/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iml/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iml/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iml/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iml/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iml/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iml/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iml/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/Inference_AllArgumentationData_5Epoch_5Fold.csv'"
     ]
    }
   ],
   "source": [
    "inference_dataframe = pd.read_csv(\"./data/inference_data.csv\")\n",
    "inf_origin_case1 = pd.read_csv(\"./data/Inference_OnlyOrigindata_1Epoch_5Fold.csv\")\n",
    "inf_origin_case2 = pd.read_csv(\"./data/Inference_OnlyOrigindata_5Epoch_5Fold.csv\")\n",
    "inf_agument_case1 = pd.read_csv(\"./data/Inference_AllArgumentationData_5Epoch_5Fold.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f0e829-0931-424a-a83b-0d4b0e6638eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_dataframe[\"origin_case1_predictions\"] = inf_origin_case1[\"predictions\"]\n",
    "inference_dataframe[\"origin_case1_pred_rate\"] = inf_origin_case1[\"pred_rate\"]\n",
    "\n",
    "inference_dataframe[\"origin_case2_predictions\"] = inf_origin_case2[\"predictions\"]\n",
    "inference_dataframe[\"origin_case2_pred_rate\"] = inf_origin_case2[\"pred_rate\"]\n",
    "\n",
    "inference_dataframe[\"agument_case1_predictions\"] = inf_agument_case1[\"predictions\"]\n",
    "inference_dataframe[\"agument_case1_pred_rate\"] = inf_agument_case1[\"pred_rate\"]\n",
    "\n",
    "# inference_dataframe.to_csv(f\"./data/merge_inference_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1ab77c-c197-4e37-ba6a-817d262a237b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_inference = pd.read_csv(\"./data/merge_inference_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71380595-858a-4a69-bf22-270224d19ba7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "want_view_data = merged_inference[[\"article\",\n",
    "                                   \"origin_case1_predictions\", \"origin_case1_pred_rate\",\n",
    "                                   \"origin_case2_predictions\", \"origin_case2_pred_rate\",\n",
    "                                   \"agument_case1_predictions\", \"agument_case1_pred_rate\"]]\n",
    "\n",
    "for idx, (item_idx, item_data) in enumerate(want_view_data.iterrows()):\n",
    "    if idx == 100:\n",
    "        break\n",
    "        \n",
    "    if (item_data[\"origin_case1_predictions\"] != item_data[\"origin_case2_predictions\"]) or \\\n",
    "        (item_data[\"origin_case2_predictions\"] != item_data[\"agument_case1_predictions\"]):\n",
    "        print(\"origin_case1 result : \", item_data[\"origin_case1_predictions\"], item_data[\"origin_case1_pred_rate\"])\n",
    "        print(\"origin_case2 result : \", item_data[\"origin_case2_predictions\"], item_data[\"origin_case2_pred_rate\"])\n",
    "        print(\"agument_case1 result : \", item_data[\"agument_case1_predictions\"], item_data[\"agument_case1_pred_rate\"])\n",
    "        print(item_data[\"article\"])\n",
    "        print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6957c8-12c3-4738-9aa3-85aaebd09d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
