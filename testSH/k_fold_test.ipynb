{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "960fc129-40a9-4e77-9ffc-66d48fa09ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 11:06:28.857275: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoModel, AutoTokenizer, DataCollatorWithPadding\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from datasets import load_dataset\n",
    "from transformers import DataCollatorWithPadding\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed9824c9-6abf-4f13-b6f7-298e95351978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal data load\n",
    "strongbuy = pd.read_csv(\"./data/strongbuy.csv\")\n",
    "sell = pd.read_csv(\"./data/sell.csv\")\n",
    "holddown = pd.read_csv(\"./data/holddown.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5a8af10-1f8a-4823-8051-cd3e49524d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand eata load\n",
    "strongbuy_expand_google_en = pd.read_csv(\"./data/strongbuy_expand_google_en.csv\")\n",
    "strongbuy_expand_google_zhcn = pd.read_csv(\"./data/strongbuy_expand_google_zhcn.csv\")\n",
    "strongbuy_expand_pororo_en = pd.read_csv(\"./data/strongbuy_expand_pororo_en.csv\")\n",
    "\n",
    "sell_expand_google_en = pd.read_csv(\"./data/sell_expand_google_en.csv\")\n",
    "sell_expand_google_zhcn = pd.read_csv(\"./data/sell_expand_google_zhcn.csv\")\n",
    "sell_expand_pororo_en = pd.read_csv(\"./data/sell_expand_pororo_en.csv\")\n",
    "\n",
    "holddown_expand_google_en = pd.read_csv(\"./data/holddown_expand_google_en.csv\")\n",
    "holddown_expand_google_zhcn = pd.read_csv(\"./data/holddown_expand_google_zhcn.csv\")\n",
    "holddown_expand_pororo_en = pd.read_csv(\"./data/holddown_expand_pororo_en.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77ec7bb6-29c9-4596-bfc9-8fee5e0fe9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>article</th>\n",
       "      <th>length</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>strongbuy65.txt</td>\n",
       "      <td> 현대엘리베이터 투자의견 STRONG BUY를 유지하며, 목표주가를 기존 108,...</td>\n",
       "      <td>519</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>strongbuy50.txt</td>\n",
       "      <td>(cid:1) 국제유가 급락 영향으로, 2014년 4분기 실적은 부진할 것으로 전망...</td>\n",
       "      <td>241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>strongbuy466.txt</td>\n",
       "      <td>기타 사업장의 수익성 예상치 또한 기대이상으로 영업이익률을 17.5%까지 기록했다는...</td>\n",
       "      <td>354</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>strongbuy301.txt</td>\n",
       "      <td>투자의견 STRONG BUY 유지, 목표주가 150,000원 상향 한국항공우주 투자...</td>\n",
       "      <td>539</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>strongbuy101.txt</td>\n",
       "      <td>LG디스플레이 (034220) - Strong Buy 17년 1분기 Preview ...</td>\n",
       "      <td>373</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>se11_content14.txt</td>\n",
       "      <td>삼성중공업 (010140 KS, REDUCE, TP: 12,100 원): 부진한 3...</td>\n",
       "      <td>798</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>strongbuy126.txt</td>\n",
       "      <td>녹십자 (006280) - STRONG BUY Investment Point - 3...</td>\n",
       "      <td>573</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2747</th>\n",
       "      <td>strongbuy59.txt</td>\n",
       "      <td>부문별 영업이익의 경우, ‘기초소재부문 3,158억원(전분기 3,212억원), 전지...</td>\n",
       "      <td>325</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>strongbuy396.txt</td>\n",
       "      <td>롯데케미칼(011170) : 다시 돌아온 그대 투자의견 Strong Buy, 목표주...</td>\n",
       "      <td>769</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2749</th>\n",
       "      <td>strongbuy208.txt</td>\n",
       "      <td>16년 모든 상황이 우호적이다. 16년 사업전망도 밝다. 1)올해도 어김없이 중국을...</td>\n",
       "      <td>308</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2750 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                filename                                            article  \\\n",
       "0        strongbuy65.txt   현대엘리베이터 투자의견 STRONG BUY를 유지하며, 목표주가를 기존 108,...   \n",
       "1        strongbuy50.txt  (cid:1) 국제유가 급락 영향으로, 2014년 4분기 실적은 부진할 것으로 전망...   \n",
       "2       strongbuy466.txt  기타 사업장의 수익성 예상치 또한 기대이상으로 영업이익률을 17.5%까지 기록했다는...   \n",
       "3       strongbuy301.txt  투자의견 STRONG BUY 유지, 목표주가 150,000원 상향 한국항공우주 투자...   \n",
       "4       strongbuy101.txt  LG디스플레이 (034220) - Strong Buy 17년 1분기 Preview ...   \n",
       "...                  ...                                                ...   \n",
       "2745  se11_content14.txt  삼성중공업 (010140 KS, REDUCE, TP: 12,100 원): 부진한 3...   \n",
       "2746    strongbuy126.txt  녹십자 (006280) - STRONG BUY Investment Point - 3...   \n",
       "2747     strongbuy59.txt  부문별 영업이익의 경우, ‘기초소재부문 3,158억원(전분기 3,212억원), 전지...   \n",
       "2748    strongbuy396.txt  롯데케미칼(011170) : 다시 돌아온 그대 투자의견 Strong Buy, 목표주...   \n",
       "2749    strongbuy208.txt  16년 모든 상황이 우호적이다. 16년 사업전망도 밝다. 1)올해도 어김없이 중국을...   \n",
       "\n",
       "      length  label  \n",
       "0        519      1  \n",
       "1        241      1  \n",
       "2        354      1  \n",
       "3        539      1  \n",
       "4        373      1  \n",
       "...      ...    ...  \n",
       "2745     798      0  \n",
       "2746     573      1  \n",
       "2747     325      1  \n",
       "2748     769      1  \n",
       "2749     308      1  \n",
       "\n",
       "[2750 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sell = pd.concat([sell, holddown])\n",
    "all_data = pd.concat([strongbuy, all_sell])\n",
    "\n",
    "# all_data = pd.concat([strongbuy, strongbuy_expand_google_en, strongbuy_expand_google_zhcn, strongbuy_expand_pororo_en,\n",
    "#                       sell, sell_expand_google_en, sell_expand_google_zhcn, sell_expand_pororo_en,\n",
    "#                       holddown, holddown_expand_google_en, holddown_expand_google_zhcn, holddown_expand_pororo_en])\n",
    "all_data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aecb10bc-3cb6-4517-923a-c62a8ec3bdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 : 0.6799\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(strongbuy)/len(strongbuy)} : {(len(sell) + len(holddown)) / len(strongbuy):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6a91312-4e94-4945-a3d2-4390721820b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(all_data, test_size=0.2, random_state=42, stratify=all_data[[\"label\"]])\n",
    "\n",
    "test_data[\"labels\"] = test_data[\"label\"]\n",
    "test_data = test_data.drop(labels=[\"filename\", \"length\", \"label\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2cb32b5-ba67-4b47-9dd0-7bcfc052630d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_length = 5\n",
    "X = train_data.drop(labels=[\"filename\", \"length\", \"label\"], axis=1)\n",
    "y = train_data[\"label\"]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=fold_length, shuffle=True, random_state=42)\n",
    "fold_dataframe = list()\n",
    "\n",
    "for fold_number, (train, valid) in enumerate(skf.split(X, y), 1):\n",
    "    X_train, X_valid = X.iloc[train], X.iloc[valid]\n",
    "    y_train, y_valid = y.iloc[train], y.iloc[valid]\n",
    "    \n",
    "    fold_train = X_train.loc[:]\n",
    "    fold_train[\"labels\"] = y_train\n",
    "    \n",
    "    fold_valid = X_valid.loc[:]\n",
    "    fold_valid[\"labels\"] = y_valid\n",
    "    \n",
    "    fold_train.to_csv(f\"./data/train_data_fold{fold_number}.csv\", index=False)\n",
    "    fold_valid.to_csv(f\"./data/valid_data_fold{fold_number}.csv\", index=False)\n",
    "\n",
    "test_data.to_csv(f\"./data/test_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80934118-b730-40a7-a091-25b34c4698fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/kb-albert-char-base-v2 were not used when initializing AlbertModel: ['predictions.decoder.weight', 'predictions.LayerNorm.weight', 'sop_classifier.classifier.weight', 'predictions.decoder.bias', 'predictions.dense.weight', 'predictions.LayerNorm.bias', 'predictions.bias', 'predictions.dense.bias', 'sop_classifier.classifier.bias']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "kb_albert_model_path = \"./model/kb-albert-char-base-v2\"\n",
    "albert = AutoModel.from_pretrained(kb_albert_model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(kb_albert_model_path)\n",
    "\n",
    "tokenizer.truncation_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da9885a5-7c0f-4ba9-a4ac-27439beed01f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-7fd20440fb06147e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-7fd20440fb06147e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f806a7dc5c0345eaae520602399a6fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19339b746a9b4fffbb4892324da7484b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-7fd20440fb06147e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8e043609df14d0e87af34781c93a4ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-7038ac638b89b583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-7038ac638b89b583/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d93e718ed754c319dce44b9838e305b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c6fa034bcdb46dab55f223b1826ff65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-7038ac638b89b583/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e7e770bd164343a8adf3af87b52a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "011ced9a95494f8d8dd6a61884d90811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1760 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f3d477bf8646ac9ad8caee264c67e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/440 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-c1f9d18edec93a8e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-c1f9d18edec93a8e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ce8b3d67554e50babb3b0b957cb9e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e4728c8ce444d6bd77b7a0c1f84383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-c1f9d18edec93a8e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6aa2061015f46eaaccc8e830a4fc925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-3c2c95d82e9ad4c4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-3c2c95d82e9ad4c4/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc2dc33e3bc42abb6f6b799a16a3226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12f4e4c848d149d0bc4ebfd2de592279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-3c2c95d82e9ad4c4/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ef92f6041b485b9d091072c2f49307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "980c2ba27c9d4dc79b5e2505b2550f29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1760 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32aab501802948cab52d35d56f874492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/440 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-d1fffbdb0a9c391f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-d1fffbdb0a9c391f/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "683e460241f04c7a9497010712f9abd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f3974cd298c4f07bcd13168315d9c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-d1fffbdb0a9c391f/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa7606f0ba41469aa766bb70b9488154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-8859db2e9a316acb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-8859db2e9a316acb/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c8e3a7131548d0b34641a7c5ec3317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2053599c624e4deba2da64e026205cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-8859db2e9a316acb/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa8f75d14aa4a538d0010d5009d45d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "136b35c70725499e8078d0a838e68ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1760 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd5bd62dd40145ebbc0cd487014ffbd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/440 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-0fe463e97c52e7a1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-0fe463e97c52e7a1/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1b6f2e62694b3fb7e2c9e2612115da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "021aeda5cc4d4e8a9d7b7abef01d2698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-0fe463e97c52e7a1/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7fcbfa0360442bcbffc52daf46484b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-cf9f7b8a5024fd69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-cf9f7b8a5024fd69/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c09d9d991cf4047ba154da8383f6f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd03135f6a1b442e8beff4ba62ddcc45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-cf9f7b8a5024fd69/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3cc7737160248b6bb7682a4fcde0052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e538e0d95e7d444b85fd534cbd3f9b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1760 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad0947e2095748ba847bae3771860eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/440 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-d6f7c2958b83ce76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-d6f7c2958b83ce76/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec655cbc6afd4b98b92d05402bd78710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c017edadef4290b43aa588f1699a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-d6f7c2958b83ce76/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "346aa7b55c3f4918b89a6c45bcabf4cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-d7e5708eb5c5cb4e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-d7e5708eb5c5cb4e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6739082df7b4b379f6724ee4be6d3a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df776d3c4b984096b57431db09893727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-d7e5708eb5c5cb4e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b86b2fc298a4572930426bbc646d13e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c039f5d5304e1dbb0b078e058b903f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1760 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d645852a3e354ee0bbc9d9b69e0a8e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/440 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-14054ea53b9fd6a7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-14054ea53b9fd6a7/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9aef55e0b01467b9e049f9db53e31a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee6a8b9700da478193e626df71dc31a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-14054ea53b9fd6a7/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d9ce7d51de4f7e97ee2024749cb7d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0d1725c353b491e8f4834cff2849366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LEN = 512\n",
    "\n",
    "def tokenized_fn(data):\n",
    "    outputs = tokenizer(data[\"article\"], padding=\"max_length\", max_length=MAX_LEN, truncation=True)\n",
    "    outputs[\"labels\"] = data[\"labels\"]\n",
    "    return outputs\n",
    "\n",
    "dataset_list = list()\n",
    "for fold_number in range(1, fold_length+1):\n",
    "    train_dataset = load_dataset(\"csv\", data_files=f\"./data/train_data_fold{fold_number}.csv\")[\"train\"]\n",
    "    valid_dataset = load_dataset(\"csv\", data_files=f\"./data/valid_data_fold{fold_number}.csv\")[\"train\"]\n",
    "\n",
    "    train_dataset = train_dataset.map(tokenized_fn, remove_columns=[\"article\"])\n",
    "    valid_dataset = valid_dataset.map(tokenized_fn, remove_columns=[\"article\"])\n",
    "    \n",
    "    dataset_list.append([train_dataset, valid_dataset])\n",
    "\n",
    "test_dataset = load_dataset(\"csv\", data_files=f\"./data/test_data.csv\")[\"train\"]\n",
    "test_dataset = test_dataset.map(tokenized_fn, remove_columns=[\"article\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15ac9d0d-6d71-4abb-89cc-5edede64a91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "dataloader_list = list()\n",
    "for train_fold, valid_fold in dataset_list:\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_fold,\n",
    "        sampler = torch.utils.data.RandomSampler(train_fold),\n",
    "        batch_size = batch_size,\n",
    "        collate_fn = data_collator,\n",
    "    )\n",
    "\n",
    "    validation_dataloader = torch.utils.data.DataLoader(\n",
    "        valid_fold,\n",
    "        sampler = torch.utils.data.SequentialSampler(valid_fold),\n",
    "        batch_size = batch_size,\n",
    "        collate_fn = data_collator,\n",
    "    )\n",
    "    \n",
    "    dataloader_list.append([train_dataloader, validation_dataloader])\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    sampler = torch.utils.data.SequentialSampler(test_dataset),\n",
    "    batch_size = batch_size,\n",
    "    collate_fn = data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96f5859f-689a-46a7-b2a0-7e583ef676b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(0.25)\n",
    "        self.out_proj = torch.nn.Linear(768, 2)\n",
    "    \n",
    "    def forward(self, features):\n",
    "        # 보통 분류기에선 start 토큰에 분류 결과를 담음\n",
    "        x = features[:, 0, :]    # take <s> token (equiv. to [CLS])\n",
    "        x = x.reshape(-1, x.size(-1))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.out_proj(x)\n",
    "        return x\n",
    "\n",
    "class AInalyst(torch.nn.Module):\n",
    "    def __init__(self, pretrained_model):\n",
    "        super(AInalyst, self).__init__()\n",
    "        self.pretrained = pretrained_model\n",
    "        self.classifier = ClassificationHead()\n",
    "    \n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None):\n",
    "        outputs = self.pretrained(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            # labels=labels\n",
    "        )\n",
    "        self.labels = labels\n",
    "        logits = self.classifier(outputs[\"last_hidden_state\"])\n",
    "        # prob = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        \n",
    "        if labels is not None:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits, labels)\n",
    "            return logits, loss\n",
    "        else:\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95223fe8-8c47-4d7f-8107-8231fe60127e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bf1f4ce-9a10-492a-b6cc-2736d78e669a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = AInalyst(pretrained_model=albert)\n",
    "model.to(device)\n",
    "model = torch.nn.DataParallel(model)\n",
    "isParallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a8a5431-14ec-4895-b3eb-58ba0e6d08ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0582000-da1b-4227-8aba-5eba428bab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05969563-c25e-4f37-8a30-90557db0f0cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ Epoch 1/5 ============\n",
      "Training...\n",
      "===== Epoch 1/5 - Fold 1/5 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piai/anaconda3/envs/iml/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Average training loss: 0.60048\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 0.78125\n",
      "===== Epoch 1/5 - Fold 2/5 =====\n",
      "\n",
      " Average training loss: 0.35368\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 0.89062\n",
      "===== Epoch 1/5 - Fold 3/5 =====\n",
      "\n",
      " Average training loss: 0.18220\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 0.95312\n",
      "===== Epoch 1/5 - Fold 4/5 =====\n",
      "\n",
      " Average training loss: 0.09401\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 0.98214\n",
      "===== Epoch 1/5 - Fold 5/5 =====\n",
      "\n",
      " Average training loss: 0.04777\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 0.99554\n",
      "===== Epoch 1/5 - Test =====\n",
      "\n",
      "Running Test...\n",
      "\n",
      " Test Accuracy: 0.92024\n",
      "\n",
      "============ Epoch 2/5 ============\n",
      "Training...\n",
      "===== Epoch 2/5 - Fold 1/5 =====\n",
      "\n",
      " Average training loss: 0.01887\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 0.99777\n",
      "===== Epoch 2/5 - Fold 2/5 =====\n",
      "\n",
      " Average training loss: 0.00897\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 2/5 - Fold 3/5 =====\n",
      "\n",
      " Average training loss: 0.00490\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 2/5 - Fold 4/5 =====\n",
      "\n",
      " Average training loss: 0.00291\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 2/5 - Fold 5/5 =====\n",
      "\n",
      " Average training loss: 0.00248\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 2/5 - Test =====\n",
      "\n",
      "Running Test...\n",
      "\n",
      " Test Accuracy: 0.93095\n",
      "\n",
      "============ Epoch 3/5 ============\n",
      "Training...\n",
      "===== Epoch 3/5 - Fold 1/5 =====\n",
      "\n",
      " Average training loss: 0.00181\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 3/5 - Fold 2/5 =====\n",
      "\n",
      " Average training loss: 0.00148\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 3/5 - Fold 3/5 =====\n",
      "\n",
      " Average training loss: 0.00128\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 3/5 - Fold 4/5 =====\n",
      "\n",
      " Average training loss: 0.00106\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 3/5 - Fold 5/5 =====\n",
      "\n",
      " Average training loss: 0.00092\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 3/5 - Test =====\n",
      "\n",
      "Running Test...\n",
      "\n",
      " Test Accuracy: 0.93750\n",
      "\n",
      "============ Epoch 4/5 ============\n",
      "Training...\n",
      "===== Epoch 4/5 - Fold 1/5 =====\n",
      "\n",
      " Average training loss: 0.00078\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 4/5 - Fold 2/5 =====\n",
      "\n",
      " Average training loss: 0.00070\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 4/5 - Fold 3/5 =====\n",
      "\n",
      " Average training loss: 0.00065\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 4/5 - Fold 4/5 =====\n",
      "\n",
      " Average training loss: 0.00055\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 4/5 - Fold 5/5 =====\n",
      "\n",
      " Average training loss: 0.00050\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 4/5 - Test =====\n",
      "\n",
      "Running Test...\n",
      "\n",
      " Test Accuracy: 0.93393\n",
      "\n",
      "============ Epoch 5/5 ============\n",
      "Training...\n",
      "===== Epoch 5/5 - Fold 1/5 =====\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9821/2648489485.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mtotal_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    print(f\"============ Epoch {epoch+1}/{epochs} ============\")\n",
    "    print(\"Training...\")\n",
    "    \n",
    "    for fold_number, (train_dataloader, validation_dataloader) in enumerate(dataloader_list, 1):\n",
    "        print(f\"===== Epoch {epoch+1}/{epochs} - Fold {fold_number}/{fold_length} =====\")\n",
    "        total_train_loss = 0\n",
    "        model.train()\n",
    "\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            batch_input_ids = batch[\"input_ids\"].to(device)\n",
    "            batch_attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            batch_labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            model.zero_grad()\n",
    "\n",
    "            logits, loss = model(\n",
    "                input_ids = batch_input_ids,\n",
    "                attention_mask = batch_attention_mask,\n",
    "                labels = batch_labels,\n",
    "            )\n",
    "\n",
    "            if isParallel:\n",
    "                loss = loss.mean()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # if step % 1000 == 0 and not step == 0:\n",
    "            #     print(\"step : {:>5,} of {:>5,} loss: {:.5f}\".format(step, len(train_dataloader), loss.item()))\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "        print()\n",
    "        print(\" Average training loss: {0:.5f}\".format(avg_train_loss))\n",
    "\n",
    "        # Validation\n",
    "        print()\n",
    "        print(\"Running Validation...\")\n",
    "\n",
    "        model.eval()\n",
    "        total_eval_accuracy = 0\n",
    "        total_eval_loss = 0\n",
    "        nb_eval_steps = 0\n",
    "\n",
    "        for step, batch in enumerate(validation_dataloader):\n",
    "            batch_input_ids = batch[\"input_ids\"].to(device)\n",
    "            batch_attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            batch_labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits, loss = model(\n",
    "                    input_ids = batch_input_ids,\n",
    "                    attention_mask = batch_attention_mask,\n",
    "                    labels = batch_labels,\n",
    "                )\n",
    "\n",
    "                if isParallel:\n",
    "                    loss = loss.mean()\n",
    "\n",
    "                total_eval_loss += loss.item()\n",
    "                logits = logits.detach().cpu().numpy()\n",
    "                label_ids = batch_labels.to(\"cpu\").numpy()\n",
    "                total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "        avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "        print()\n",
    "        print(\" Valid Accuracy: {0:.5f}\".format(avg_val_accuracy))\n",
    "    \n",
    "    # Test\n",
    "    print(f\"===== Epoch {epoch+1}/{epochs} - Test =====\")\n",
    "    print()\n",
    "    print(\"Running Test...\")\n",
    "\n",
    "    model.eval()\n",
    "    total_test_accuracy = 0\n",
    "    total_test_loss = 0\n",
    "    nb_test_steps = 0\n",
    "    \n",
    "    for step, batch in enumerate(test_dataloader):\n",
    "        batch_input_ids = batch[\"input_ids\"].to(device)\n",
    "        batch_attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        batch_labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits, loss = model(\n",
    "                input_ids = batch_input_ids,\n",
    "                attention_mask = batch_attention_mask,\n",
    "                labels = batch_labels,\n",
    "            )\n",
    "\n",
    "            if isParallel:\n",
    "                loss = loss.mean()\n",
    "\n",
    "            total_test_loss += loss.item()\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = batch_labels.to(\"cpu\").numpy()\n",
    "            total_test_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "    avg_test_accuracy = total_test_accuracy / len(test_dataloader)\n",
    "    print()\n",
    "    print(\" Test Accuracy: {0:.5f}\".format(avg_test_accuracy))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06109df5-d5e7-421d-9012-04578ce923a5",
   "metadata": {},
   "source": [
    "## Model Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba39b1e-c0a9-4510-9d55-8e42d5f11138",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./model/kbalbert_epoch5_fold5.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8dfe35-2c5f-41e8-bbb7-8ff2717ca604",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fec8ff9-0a6d-4d56-8d03-27f571a6da59",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = AInalyst(pretrained_model=albert)\n",
    "load_model.to(device)\n",
    "load_model = torch.nn.DataParallel(load_model)\n",
    "load_model.load_state_dict(torch.load(\"./model/kbalbert_epoch5_fold5.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60689f07-5a60-4029-875c-540b997341e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_tokenized_fn(data):\n",
    "    outputs = tokenizer(data[\"article\"], padding=\"max_length\", max_length=MAX_LEN, truncation=True)\n",
    "    return outputs\n",
    "\n",
    "inference_dataset = load_dataset(\"csv\", data_files=f\"./data/inference_data.csv\")[\"train\"]\n",
    "inference_dataset = inference_dataset.map(inference_tokenized_fn,\n",
    "                                          remove_columns=[\"Unnamed: 0\", \"company\", \"title\", \"opinion\", \"firm\", \"date\", \"article\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd4a261-c965-4c23-b541-100dcd01f2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_dataloader = torch.utils.data.DataLoader(\n",
    "    inference_dataset,\n",
    "    sampler = torch.utils.data.SequentialSampler(inference_dataset),\n",
    "    batch_size = 1,\n",
    "    collate_fn = data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eaf7e1-56fc-4c9e-ac95-2d7dd36d21fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model.eval()\n",
    "\n",
    "probabilities = list()\n",
    "predictions = list()\n",
    "\n",
    "for step, batch in enumerate(tqdm(inference_dataloader, desc=\"inference\", mininterval=0.1)):\n",
    "    batch_input_ids = batch[\"input_ids\"].to(device)\n",
    "    batch_attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = load_model(\n",
    "            input_ids = batch_input_ids,\n",
    "            attention_mask = batch_attention_mask,\n",
    "        )\n",
    "        \n",
    "        prob = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        predict = torch.argmax(prob, axis=1)\n",
    "        \n",
    "        prob = np.round(np.max(prob.detach().cpu().numpy(), axis=1) * 100, 2)\n",
    "        predict = predict.detach().cpu().numpy()\n",
    "        \n",
    "        probabilities.append(prob[0])\n",
    "        predictions.append(predict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83876235-0f08-43ae-87eb-47af4e164747",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_dataframe = pd.read_csv(\"./data/inference_data.csv\")\n",
    "\n",
    "convert_predictions = list(map(lambda x: \"매수\" if x == 1 else \"매도\", predictions))\n",
    "inference_dataframe = inference_dataframe.drop(labels=\"Unnamed: 0\", axis=1)\n",
    "inference_dataframe[\"predictions\"] = convert_predictions\n",
    "inference_dataframe[\"pred_rate\"] = probabilities\n",
    "inference_dataframe.to_csv(f\"./data/convert_inference_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803aa4a6-e9eb-4304-b7e1-ba8923c32777",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_dataframe[\"predictions\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d9dad7-797b-4998-a41f-14b8418310d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_num = 0\n",
    "rl_num = 20\n",
    "\n",
    "# for arti, pred, pred_rate in zip(inference_dataframe[\"article\"][ll_num:rl_num], inference_dataframe[\"predictions\"][ll_num:rl_num], inference_dataframe[\"pred_rate\"][ll_num:rl_num]):\n",
    "#     print(pred, pred_rate)\n",
    "#     print(arti)\n",
    "#     print(\"=\" * 50)\n",
    "\n",
    "# for arti, pred, pred_rate in zip(inference_dataframe[\"article\"], inference_dataframe[\"predictions\"], inference_dataframe[\"pred_rate\"]):\n",
    "#     if pred_rate < 90:\n",
    "#         print(pred, pred_rate)\n",
    "#         print(arti)\n",
    "#         print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc901d8e-3916-497c-9a05-b6ec3247ee27",
   "metadata": {},
   "source": [
    "## Inference Data들 Merge해서 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0c90125-29ed-4946-a09b-fb4d8f6523cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_dataframe = pd.read_csv(\"./data/inference_data.csv\")\n",
    "inf_origin_case1 = pd.read_csv(\"./data/Inference_OnlyOrigindata_1Epoch_5Fold.csv\")\n",
    "inf_origin_case2 = pd.read_csv(\"./data/Inference_OnlyOrigindata_5Epoch_5Fold.csv\")\n",
    "inf_agument_case1 = pd.read_csv(\"./data/Inference_AllArgumentationData_5Epoch_5Fold.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45f0e829-0931-424a-a83b-0d4b0e6638eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_dataframe[\"origin_case1_predictions\"] = inf_origin_case1[\"predictions\"]\n",
    "inference_dataframe[\"origin_case1_pred_rate\"] = inf_origin_case1[\"pred_rate\"]\n",
    "\n",
    "inference_dataframe[\"origin_case2_predictions\"] = inf_origin_case2[\"predictions\"]\n",
    "inference_dataframe[\"origin_case2_pred_rate\"] = inf_origin_case2[\"pred_rate\"]\n",
    "\n",
    "inference_dataframe[\"agument_case1_predictions\"] = inf_agument_case1[\"predictions\"]\n",
    "inference_dataframe[\"agument_case1_pred_rate\"] = inf_agument_case1[\"pred_rate\"]\n",
    "\n",
    "inference_dataframe.to_csv(f\"./data/merge_inference_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a1ab77c-c197-4e37-ba6a-817d262a237b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_inference = pd.read_csv(\"./data/merge_inference_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "71380595-858a-4a69-bf22-270224d19ba7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin_case1 result :  매도 86.0\n",
      "origin_case2 result :  매도 90.0\n",
      "agument_case1 result :  매수 99.91\n",
      "\n",
      "\n",
      "2Q22 Review : 높아진 컨센서스 상회LG이노텍의 2분기 매출액 3조 7,026억원(YoY+57.2%, QoQ-31.0%), 영업이익 2,899억원(YoY+83.7%, QoQ-21.0%) 최근 높아진 컨센서스 영업이익(매출액 3조 2,783억원, 영업이익2,545억원)을 상회하는 호실적을 발표. 광학솔루션사업부는 우호적인 환율속에 고객사의 판매량 호조와 높은 고부가 제품 비중효과가 작용. 기판소재사 업부는 1Q22부진했던 디스플레이 제품군의 양호한 실적과 반도체 패키지 기판의 견조한 수요와 생산능력 확대 효과 반영. 전장부품사업부는 차량용 통신모듈 및 모터가 증가 했으나 원자재 가격상승영향으로 수익성 개선이 지연.\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매수 99.0\n",
      "origin_case2 result :  매수 97.0\n",
      "agument_case1 result :  매도 97.92\n",
      "\n",
      "\n",
      "투자의견 ‘매수’ 및 목표주가 150,000원 유지. 최대 실적 다시 경신삼성물산에 대해 투자의견 ‘매수’ 및 목표주가 150,000원 유지. 2Q22 실적은 글로벌 원자재 가격 상승•공급망 훼손 등 경영환경 악화 불구, 경영체질 개선 및 사업 경쟁력 강화 노력에 힘입어 외형과 수익성 모두 크게 개선, 역대 최대 영업이익 경신. 2분기 연속 실적 서프라이즈로 목표주가 상향요인 있으나, 여전한 목표 주가 괴리율과 최근 글로벌 경기 침체 우려에 따른 자회사 지분 가치 하락 리스크를 감안 목표주가 유지. ① 1H22 건설부문 신규 수주는 계열사 신규 투자, 베트남 복합 발전 등 8.6조원으로 연간목표 11조원 대비 73.5% 달성. ② 매출화 빠른 하이테크 공사 진행률 증가, 상사를 포함한 사업 전부문 안정적 이익 체력 구축으로 합병 이후 최초로 연간 영업이익 2조원 달성 전망. 매수 추천.\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매도 98.0\n",
      "origin_case2 result :  매도 99.0\n",
      "agument_case1 result :  매수 70.92\n",
      "\n",
      "\n",
      "2Q22 실적 Review연결 매출 6,514억(QoQ +27.4%, YoY +58.0%), OP 1,697억(QoQ -3.8%, YoY +1.7%) 기록. 2Q22 실적에는 이전까지 지분법으로 반영되던 에피스 실적이 연결로 반영되어 QoQ, YoY 단순 비교 어려워 별도 매출 5,037억, OP 1,719억 기록. 2공장 정기유지보수 영향으로 가동률 소폭 하락하였으나 환율 및 3공장 판매량 증가하며 호실적 기록 에피스 매출 2,328억, OP 585억 기록. 다만 이번 연결 실적에는 5월-6월분인 매출 1,494억 OP 300억 반영\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매도 85.0\n",
      "origin_case2 result :  매수 97.0\n",
      "agument_case1 result :  매수 99.98\n",
      "\n",
      "\n",
      "2Q22 Review: 2분기 기준 최대 실적LG이노텍의 22년 2분기 매출액은 3조 7,026억원(YoY +57%, QoQ -6%), 영업이익은 2,899억원(YoY +91%, QoQ -21%)을 기록했다. 이는 컨센서스를 각각 13%, 14% 상회하는 호실적이다. 예상보다 양호한 실적을 기록한 이유는 1) 우호적인 환율 속에서 2) iPhone 13 시리즈(Pro, Pro Max)의 판매 호조, 3) 패키지기판의 견조한 수요 때문이다. 전장 부품도 우려와 달리 전분기대비 매출액이 증가했다.\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매수 84.0\n",
      "origin_case2 result :  매수 99.0\n",
      "agument_case1 result :  매도 99.96\n",
      "\n",
      "\n",
      "매출액 및 영업이익 모두 시장기대치 크게 상회하며 3분기 연속 사상최대 분기실적 경신- 매출액 31% YoY(시장기대치 상회), 영업이익 63% YoY(시장기대치 상회, OPM 25%)- 품목별 매출 (연결기준): 의료디텍터 14% YoY, 산업카메라 69% YoY, 치과디텍터 9% YoY, NDT 92% YoY, 기타 -8% YoY- 지역별 매출(별도기준): 북미 13% YoY, 유럽 36% YoY, 일본 -29% YoY, 중국 69% YoY, 대한민국 33% YoY, 기타 51% YoY\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매도 86.0\n",
      "origin_case2 result :  매도 94.0\n",
      "agument_case1 result :  매수 99.97\n",
      "\n",
      "\n",
      "1. 2Q22 잠정실적: 별도 기준 컨센서스 상회하는 실적 기록- 삼성바이오로직스 별도 매출액 5,037억원(+22.2%YoY, -1.5%QoQ), 영업이익 1,719억원(+3.1%YoY, -2.4%QoQ) 기록. 삼성바이오에피스 연결을 제외한 컨센서스 매출액 4,573억원, 영업이익 1,487억원 상회- 삼성바이오에피스 별도 매출액 2,328억원(+24.1%YoY, +16.9%QoQ), 영업이익 585억원(+95.7%YoY,+68.6%QoQ) 기록- 삼성바이오로직스 연결 매출액 6,514억원(+58.1%YoY, +27.4%QoQ), 영업이익 1,697억원(+1.8%YoY, -3.8%QoQ) 기록. 2분기 중 삼성바이오에피스를 연결대상 종속회사로 편입. 4월까지는 삼성바이오에피스를 지분법 회계처리, 5월부터는 연결 회계처리하여 반영된 실적- 2공장 정기보수에도 불구하고 우호적 환율 효과(1Q22 평균 환율 1,204원/달러, 1Q21 평균 환율 1,114원/달러)와 배치 효율화로 호실적 기록\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매수 87.0\n",
      "origin_case2 result :  매도 93.0\n",
      "agument_case1 result :  매수 81.48\n",
      "\n",
      "\n",
      "2Q22 Review: 환율효과에 삼성바이오에피스까지2Q22 실적은 연결 기준 6,514억원(+58.1% yoy, +27.4% qoq), 영업이익 1,697억원(+1.8% yoy, -3.8% qoq), 당기순이익 1,520억원(+25.1% yoy, +3.5% qoq)으로 컨센서스를 상회했다. 별도 기준으로도 5,037억원에 1,719억원을 기록하였기 때문에 1Q22의 어닝 서프라이즈를 유지한 것이며, 연결 실적은 삼성바이오에피스의 상각비 반영 및 내부 거래 소거 등이 반영됐다. 제2공장 정기유지보수로 인한 영업이익 감소에도 불구하고 1) 2Q22부터 삼성바이오에피스 연결 반영, 2) 환율 효과, 3) 삼성바이오에피스 신제품 출시 및 마일스톤 매출 인식, 4) 3공장 가동률 및 판매량 증가로 인해 컨센서스를 상회했다.\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매도 53.0\n",
      "origin_case2 result :  매수 96.0\n",
      "agument_case1 result :  매수 91.01\n",
      "\n",
      "\n",
      "2Q22 Review: 실적 고성장 지속2Q22 연결 기준 매출액은 10.8조원(+26.6% YoY), 영업이익은 5,559억원(+30.8% YoY)으로 시장 컨센서스(10.2조원, 4,859억원)를 큰 폭으로 상회하며 고성장세를 이어갔다. 모든 사업부의 매출액과 영업이익이 호실적을 기록했다. 특히 레저 부문이 코로나 이전 수준을 회복했다는 점이 인상적이다. 1) 건설부문은 매출액 3.4조원(+26.3% YoY), 영업이익 1,550억(+37.2% YoY)을 기록했다. 평택 반도체 3기 공정 호조 등으로 건축부문의 매출액이 2.2조원(+53.0% YoY)으로 증가하며 성장을 견인했다. 1H22 건설부문의 수주 실적은 8.6조원(1Q 4.9조원, 2Q 3.7조원)으로 연간 가이던스(11.7조원, 달성률 74%) 초과 달성이 예상된다. 2)상사부문은 매출액 5.4조원(+26.0% YoY), 영업이익 1,290억원(+43.3% YoY)을 기록했다. 일부 트레이딩 매출 감소에도 오텔리녹스 정밀재 공장의 효율성 제고 등으로 성장을 이어간 것으로 파악된다. 사회적 거리두기 해제로 레저, 패션, 식음의 실적 개선이 두드러졌다. 특히 레저부문의 매출액은 2,200억원(4Q19 1,820억원), 영업이익 220억원(4Q19 230억원)으로 코로나 이전 수준을 회복했다.\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매도 98.0\n",
      "origin_case2 result :  매도 91.0\n",
      "agument_case1 result :  매수 99.98\n",
      "\n",
      "\n",
      "해외 플랜트 현장 1천억원 매출 차감 반영GS 건설의 2 분기 매출액은 3 조 479 억원으로 전년동기대비 36.6% 증가, 컨센서스 대비 15.2% 상회했다. 이는 지난 3 월부터 연결 실적으로 반영되고 있는 자이씨앤에이 (구 S&I 건설)의 매출액 5,400 억원 반영에 기인한다. 반면 영업이익은 1,644 억원으로 전년동기대비 31.6% 증가, 컨센서스 영업이익 1,805 억원 대비 8.9% 하회하는 실적을 기록했다. 이는 금번분기 이라크 카르발라 정유 현장의 매출 1 천억원 차감 효과에 따른 원가율 상승이 있었기 때문이다. 이라크 카르발라 정유는 1 분기 분기보고서 기준 공사미수금 1,757 억원, 미청구공사미수금 206 억원이 계상되어 있다. 모든 공사미수금이 손실은 아니기 때문에, 금번 분기 비교적 대규모의 비용 반영 덕분에 향후 플랜트 부문 추가 원가 상승 가능성은 제한적으로 판단한다. 건축/주택의 경우는 예정원가 미확정 현장들의 순차적 확정 및 준공정산이익 반영으로 마진율 개선세를 확인할 수 있었으나, 준공정산이익이 제거된 3 분기 마진의 경우는 건자재 가격 상승분을 고려시 다소 눈높이를 낮춰야 할 것으로 추정하고 있다. 상반기 누계 분양은 11,000 여세대로 고금리하에서의 수요 위축 상황에서도 분양 성과가 우호적인 점은 고무적이다.\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매도 77.0\n",
      "origin_case2 result :  매수 99.0\n",
      "agument_case1 result :  매도 99.94\n",
      "\n",
      "\n",
      "우려의 방향성에 의지할 것인가? 막연한 회복 시점을 바라볼 것인가?- 중국 스마트폰의 지난 3 ~ 5월간 평균 출하량은 2,000만대 전후로 코로나 발발 이후 최저수준 기록. 중국 락다운 영향이 반영된 극한 수치로 향후 동수준의 출하량을 가정하더라도 YoY 역성장 폭은 축소될 것으로 전망- 4, 5월 중국 소비자신뢰지수는 지수 역사상 최저치(86 대)를 기록하며 극한의 수요 위축 상황을 대변. 한편, 중국 PMI 지수는 4월 저점 형성 이후 반등한 것을 고려하면 스마트폰 수요 전망이 현시점 대비 추가 악화될 가능성은 낮을 것으로 판단- 두차례의 걸친 Amazon의 서버 내용연수 연장과 감가상각비 변경에서 역산한 Hyperscaler들의 보유 서버 자산과 잠재적 교체 대상의 규모가 최근 2년간 급격히 증가한 것으로 추정하기에 Capex 하향 조정은 장기화 되지 않을 것으로 판단- 더욱이, 금일 공시된 Meta의 2Q22 Capex는 $7.7B으로 전분기 대비 40% 증액되었을 뿐만 아니라 22년 가이던스를 기존 $29B ~ 34B에서 $30B ~ 34B로 변경하며 최소 투자액의 상향 뿐만 아니라 하반기 투자 가시성이 높아짐- 동사는 금일 컨퍼런스콜을 통해 하반기 업황 향방에 따라 23년 Capex에 대한 보수적 시나리오를 고려하고 있음을 언급. 19년 Capex 축소 당시 대비 상대적으로 건전한 재고 상황에서의 선제적 시나리오 수립은 학습에 기반한 순발력 있는 결정으로 판단- 당사는 DRAM 고정가 상승 시점을 23년 3월로 전망하며 1) 23년 공급 조절 효과의 발현, 2) Hyperscaler의 투자 확대기(MSFT) 도래와 신규 투자 계획 집행(Meta), 3) 플래그쉽 스마트폰 신제품 출시와 중국 춘절 이후 재고 Build up 효과 등에 근거함\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매도 51.0\n",
      "origin_case2 result :  매수 98.0\n",
      "agument_case1 result :  매수 99.98\n",
      "\n",
      "\n",
      "목표주가 75만원으로 15.4% 상향, 매수 의견 유지- 화학 섹터의 다운사이클에도 불구, 전지 소재 사업의 급성장을 반영하여 목표주가 상향- 급격한 성장: 지난 반년간 전지 소재 매출액 약 3배 증가. 하반기에도 추가 성장 기대- 마진 개선: 경쟁사(10% 초반) 대비 높은 수익성(2Q 전지 소재 OPM 23% 추정)- 저평가: LG엔솔의 지분가치를 반영하지 않아도 현 주가는 저평가 구간으로 판단\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매도 62.0\n",
      "origin_case2 result :  매도 82.0\n",
      "agument_case1 result :  매수 97.04\n",
      "\n",
      "\n",
      "컨센서스 상회하는 호실적 기록- 매출액 3,162억원(+13% YoY), 영업이익 314억원(+98% YoY), 순이익 245억원(+196% YoY) 기록. 매출액, 영업이익, 순이익이 컨센서스를 +4%, +33%, +24% 상회- 한미약품의 안정적 성장, 북경한미 고성장, 한미정밀화학 흑자전환- 한미약품: 로수젯(고지혈), 아모잘탄(고혈압), 에소메졸(위식도역류) 등 주력 제품 성장 북경한미: 진해거담제 이탄징, 이안핑 등 호흡기 품목 고성장, 주요 제품 점유율 유지.- 2Q22 R&D 비용은 매출 대비 12.5%. R&D 효율화 기조 유지(20년 20%, 21년 12%)\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매수 65.0\n",
      "origin_case2 result :  매도 99.0\n",
      "agument_case1 result :  매수 99.83\n",
      "\n",
      "\n",
      "1H22보다 재미있어질 2H22 주목2Q22 매출액 776억원(-7.3% YoY), 영업이익 74억원(-28.7% YoY)으로 전분기와 유사한 실적 기록할 것으로 예상. 1H22 주력 아티스트 활동 부재했으나, 8월 블랙핑크 완전체 컴백이 22개월만에 이루어짐에 따라 3Q22 기점으로 본격적인 어닝 사이클 진입 기대 2Q22 부문별 실적은 [앨범/DVD]매출 84억원(+45.0% YoY), [디지털콘텐츠]매출은 140억원(-22.5% YoY), [Goods]매출 85억원(-15.0% YoY), [출연료]매출은 63억원(+4.3%, YoY), [로열티]매출은 30억원(+24.5%, YoY), [음악서비스]매출 187억원(+12.5%, YoY)으로 전분기와 유사한 수준 기록할 것으로 예상. 주력 아티스트의 직접적인 활동이 부재한만큼 전체 매출 가운데 아티스트 IP를 활용한 간접매출 비중이 1H22에는 높을 것. 동사 아티스트 직접적인 활동이 부재하더라도 분기별 매출 700~800억원, 영업이익 60~80억원 이익 유지 가능\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매도 84.0\n",
      "origin_case2 result :  매수 99.0\n",
      "agument_case1 result :  매수 99.85\n",
      "\n",
      "\n",
      "판매가격 인상 영향 호실적 기록- 2분기 매출 7.4조원(+31.3% YoY), 영업이익 0.8조원(+50.8% YoY)으로 예상에 부합하는 호실적 기록- 화물연대 파업으로 판매량 소폭 감소했음에도 불구하고 호실적을 기록한 배경은 판매가격 인상이 컸을 것으로 추정. 현대제철은 상반기 자동차강판 15만원, 조선용후판 10만원 인상한 것으로 알려짐.\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매도 99.0\n",
      "origin_case2 result :  매도 99.0\n",
      "agument_case1 result :  매수 96.29\n",
      "\n",
      "\n",
      "2Q22 실적 Review연결 매출 3,164억(QoQ -1.5%, YoY +13.3%), OP 314억(QoQ -23.2%, YoY + 98.0%) 기록. 당사 추정치(296억) 및 컨센서스(236억) 대비 상회 개별 기준 매출 2,373억(QoQ +4.7%, YoY +6.6%), OP 135억(QoQ -8.2%, YoY +32.4%)로수젯, 아모잘탄, 에소메졸 등 주력 제품의 매출이 안정적으로 성장 중북경한미 785억(QoQ -17.2%, YoY +31.9%), OP 171억(QoQ -32.9%, YoY +98.8%) 기록. 이탄징 등 유아용 진해거담제와 리똥 등 변비약의 매출이 안정적으로 성장. 다만 통상적인 계절적 비수기 영향으로 QoQ로는 소폭 감익 한미정밀 239억(QoQ +15.9%, YoY +8.6%), OP 2억(QoQ -72.0%, YoY -108.0%) 기록\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매도 81.0\n",
      "origin_case2 result :  매수 99.0\n",
      "agument_case1 result :  매도 99.96\n",
      "\n",
      "\n",
      "예상치에 부합한 실적. 자본비율 개선에 따라 중간배당도 실시JB금융에 대한 투자의견 매수와 목표주가 10,000원을 유지. 2분기 순익은 전분기대비 8.1% 감소한 1,532억원을 시현해 컨센서스를 소폭 하회했지만 우리예상치에는 부합. 1) 미래 경기 전망 반영한 보수적 충당금 115억원 추가 적립에도 불구하고 NIM 상승에 따른 순이자이익 증가로 은행 이익은 견조한 모습이었지만 2) 시장금리 급등에 따라 캐피탈 조달비용이 상승하고 FVPL 유가증권평가손 확대 등으로 인해 캐피탈 순익이 감소한 점이 전분기대비 그룹 순익이 감소한 주요 배경임. 그룹 내부등급법 승인에 따라 보통주자본비율이 103bp 개선되는 효과가 나타나면서 2분기 그룹 CET 1 비율은 약 11.2%로 전분 기대비 94bp 상승했고, 개선된 자본력을 바탕으로 주당 120원의 중간배당을 결정. 중간배당 실시는 지방은행 중 최초임. 지방은행 중 가장 안정적인 펀더멘털을 보유하고 있으며 배당성향도 지속적으로 상향되는 등 주주환원정책에도 적극적인 모습\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매도 92.0\n",
      "origin_case2 result :  매도 94.0\n",
      "agument_case1 result :  매수 99.98\n",
      "\n",
      "\n",
      "2Q22 Review: 매출액 236억원(+41% yoy), 영업이익 83억원(+34% yoy)2Q22 잠정 매출액은 236억원(+41% yoy, +60% qoq)), 영업이익 83억원(+34% yoy, +77% qoq)으로 컨센서스 대비 매출액은 +8%, 영업이익은 +15% 상회하는 호실적을 기록했다. 매출액 서프라이즈는 상반기 출신한 신제품(1Q22 노우즈 패치, 2Q22 페이스, 마이크로니들) 효과로 여드름 패치를 제외한 3개 신제품의 수출 매출액은 70억원, 수출매출 내 기여도는 46%에 달한 것으로 추정된다. 2Q22에는 원가율이 전분기와 동일한 56% 수준으로 파악되고, 특별한 판관비성 비용 반영이 없어 영업이익률은 35%(-2%p yoy, +2%p qoq)를 기록하며 영업레버리지 효과가 확인되었다.\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매도 97.0\n",
      "origin_case2 result :  매수 94.0\n",
      "agument_case1 result :  매도 99.96\n",
      "\n",
      "\n",
      "고수익성 유지2022년 2분기 순이익은 1,532억원으로 시장예상에 부합. 이자이익과 수수료이익 증가세가 이어졌으나 유가증권 평가손 영향으로 기타 비이자이익 규모가 축소되면서 총영업이익은 전분기와 유사한 수준을 기록. 판관비는 낮게 유지되었으나 1분기에 이어 미래 경기전망을 반영한 추가충당금 인식(115억원)으로 전분기 대비 이익규모가 소폭 둔화. 하지만 연환산 ROE가 15%에 달해 업종 최고 수익성 기조를 유지한데다 그룹 내부등급법 승인으로 보통주 자본비율이 103bp 개선되며 11.2%까지 상승. 이에 주당 120원의 중간배당을 시행함\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매수 87.0\n",
      "origin_case2 result :  매수 99.0\n",
      "agument_case1 result :  매도 99.96\n",
      "\n",
      "\n",
      "매출 및 영업이익 모두 시장 기대치 크게 상회하며, 사상최대 분기실적 기록- 매출 32% YoY(시장 기대치 상회), 영업이익 64% YoY(OPM 21%, 시장 기대치 상회)- 지역(YoY 생략): 국내 및 수출 30%, 해외 42%(중국 28%, 미국 48%, 러시아 66%)\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매도 99.0\n",
      "origin_case2 result :  매도 99.0\n",
      "agument_case1 result :  매수 99.98\n",
      "\n",
      "\n",
      "매출액 3,391억원(+109% YoY) 및 영업이익 241억원(흑자전환 YoY) 잠정실적 발표- 당사 추정 영업이익 207억원 및 컨센서스 215억원을 각 15%, 12% 상회- 수익성 개선이 가능하였던 요인은 1) 계절적 비수기에도 북미 고객사의 견조한 출하량이 지속되며 높은 수준의 가동률이 유지되고 있는 것으로 추정하며, 2) 특히 최상위 모델의 판매 비중이 높아 제품 믹스 효과가 크게 나타난 것으로 예상, 3) 원/달러 환율이 1,300원 이상을 기록하며 마진에 긍정적이기 때문\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매수 99.0\n",
      "origin_case2 result :  매수 69.0\n",
      "agument_case1 result :  매도 99.96\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t■ 제지 원재료인 펄프 생산을 내재화한 국내 유일 업체. 펄프-제지 일관화로 공정 효율화 달성하여 원가 경쟁력 확보. 연간 매출의 37%가 수출에서 발생■ 펄프 가격의 가파른 상승으로 2분기부터 펄프사업 흑자 전환 예상. 1분기 호실적 주요인인 제지의 경우 하반기 중 추가 판가 인상 가능■ 2022년 연간 실적은 매출액 7,251억원(+18.2% YoY), 영업이익 580억원(+97.4% YoY) 예상\n",
      "\t\t\t\t\t\t\t\n",
      "==================================================\n",
      "origin_case1 result :  매도 92.0\n",
      "origin_case2 result :  매수 99.0\n",
      "agument_case1 result :  매수 99.89\n",
      "\n",
      "\n",
      "예상치 부합하는 실적 발표- 2분기 매출 23조원, 영업이익 2.1조원으로 예상치 부합- 철강 부문 영업이익 1.8조원, 원료탄 사용단가 상승에도 불구 판매가격 상승으로 전분기비 5% 증가- 비철강 부문 영업이익 5,330억원으로 전분기비 5.3% 증가하며 이익 견조세 지속, 단 포스코에너지는 계절적 전력 비수기 영향에 따른 전력수요 감소와 판가 하락 영향으로 이익 감소\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매도 80.0\n",
      "origin_case2 result :  매수 99.0\n",
      "agument_case1 result :  매수 99.97\n",
      "\n",
      "\n",
      "절강포화 실적 연결로 고성장 지속- 매출 8,032억원(+67.3% YoY), 영업이익 552억원(+55.1% YoY)로 고성장 지속- 양극재 매출 3,470억원으로 전분기비 27.4% 증가, 이는 2분기부터 절강포화가 종속법인으로 바뀐 영향이 큰 것으로 판단, 절강화포로부터 전구체를 공급받는 절강포화의 수익성이 높아 전체 수익성 상승에 영향 끼친 것으로 추정- 음극재 매출 465억원으로 전분기비 3.6% 증가, 판매량 소폭 감소에도 불구 환율 상승\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매도 96.0\n",
      "origin_case2 result :  매수 87.0\n",
      "agument_case1 result :  매수 99.97\n",
      "\n",
      "\n",
      "목표주가 53,000원 유지. 예상 수준의 2Q22 실적현대건설에 대해 투자의견 ‘매수’ 및 목표주가 53,000원 유지. 최근 주가는 글로벌 인플레이션에 따른 비용 증가 부담과 해외 실적 우려 등으로 하락. 하지만 2Q22 실적은 원가율 악화 불구, 해외 매출액 증가에 힘입어 전년비 이익 개선. 상반기 신규수주는 주택/건축 신규 수주에 힘입어 21.0조원(YoY +14.3%, 연간 수주계획 28조원 대비 75.0% 달성)으로 급증, 누적 수주잔고는 90.7조원으로 역대 최대치 달성. ① 늘어난 수주잔고 + 분양 증가에 힘입어 중장기적 매출액 증가가 기대되고, ② 멀티플 상승에 도움이 되는 해외 매출액 증가가 시작되었고, ③ 국제유가 고레벨 유지에 따른 하반기 산유국 발주 증가가 기대되는 점을 감안하면 최근 주가 하락은 매수 기회로 판단\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매수 97.0\n",
      "origin_case2 result :  매수 84.0\n",
      "agument_case1 result :  매도 99.96\n",
      "\n",
      "\n",
      "종합 반도체 후공정 장비 회사한미반도체는 종합 반도체 후공정 장비회사로, 대부분 공정에 사용되는 핵심장비 및 보조장비 생산. 글로벌 OSAT 및 PCB업체 등 약 320여개 고객사와 거래하고 있으며, 2021년 micro SAW를 내재화 하여, MSVP에서 높은 매출 성장을 시현.\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매도 97.0\n",
      "origin_case2 result :  매수 99.0\n",
      "agument_case1 result :  매도 99.95\n",
      "\n",
      "\n",
      "은행 중 가장 큰폭의 NIM 개선. 비이자 부진을 충분히 상쇄신한지주에 대한 투자의견 매수와 목표주가 50,000원을 유지. 2분기 순익은 전분기대비 5.7% 감소한 약 1.32조원으로 컨센서스와 우리예상치에 부합. 1) 투자금융수수료와 기타수수료 감소로 그룹수수료이익이 감소하고, 금리 상승에 따른 은행 유가증권관련익 710억원 감소와 보험관련이익 260억원 감소로 비이자이익이 다소 저조했던데다 2) 미래 경기전망 반영 충당금을 2,250억원이나 추가 적립했지만 3) 은행 NIM이 12bp 상승하면서 순이자이익이 전분기대비 6.8%나 급증했고, 4) 디지털투자비용 증가에도 판관비는 YoY 2.6% 증가에 그쳤으며, 5) 신한카드 부동산 매각익 630억원 등으로 영업외이익도 선방했기 때문. 3분기 중 신한금투 사옥 매각익 4,400억원(세후 3,200억원)이 추가 반영되면 3분기 추정 순익은 약 1.7조원에 달하고, 올해 연간 순익은 5.3조원을 상회할 수 있을 전망\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매도 67.0\n",
      "origin_case2 result :  매수 99.0\n",
      "agument_case1 result :  매수 99.91\n",
      "\n",
      "\n",
      "국내 매출 본격화, 해외 매출 성장세 지속현대건설의 2 분기 매출액은 5 조 5,794 억원으로 전년동기대비 27.3% 증가, 컨센서스대비 14.6% 상회했다. 이는 현대엔지니어링의 해외 부문에서 인도네시아 발릭파판 정유 현장의 JV 시공사 지분 인수에 따른 일회성 요인에 기인한다. 영업이익은 1,754 억원으로 컨센서스 영업이익 1,823 억원에 비교적 부합했다. 국내 매출의 경우 2 분기 대형 현장 본격 기성 램프업에 따라 성장성 회복을 확인했으며, 해외 부문의 경우 일회성 매출 성장분을 제외하고 보더라도 사우디 마잔, 이라크 바스라 정유 등의 대형공사의 매출 본격화로 성장성이 지속되고 있는 점은 긍정적이다. 마진의 경우 건자재 가격 상승과 더불어 이라크 카르발라 정유 현장의 일회성 비용 반영에 따라 낮아진 컨센서스 눈높이에 부합하는 무난한 수준으로 판단한다.\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매도 86.0\n",
      "origin_case2 result :  매수 80.0\n",
      "agument_case1 result :  매도 78.44\n",
      "\n",
      "\n",
      "큰 폭의 이자이익 증가가 호실적 배경2022년 2분기 순이익은 1.32조원을 기록해 시장예상에 부합하는 양호한 실적 시현. 대손 비용 증가와 비이자이익 둔화에도 큰 폭의 순이자마진 상승에 힘입어 이자이익 증가 폭이 확대되며 분기 ROE 12% 수준의 고수익성 유지. 특이요인으로는 경기대응 충당금 2,245억원 적립과 카드 사옥 매각이익 627억원이 있었음. 아직 분기배당 규모는 결정되지 않았으나 호실적 감안시 1분기와 동일한 주당 400원으로 추정. 추가비용 인식에도 높은 이익 규모가 유지되고 있어 1분기 실적에 대한 긍정적 평가 가능\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매도 98.0\n",
      "origin_case2 result :  매수 85.0\n",
      "agument_case1 result :  매도 97.24\n",
      "\n",
      "\n",
      "긍정적 환율 효과, 판매 믹스 개선 등으로 호실적 기록- 2분기 영업이익 2.2조원으로 컨센서스 상회: 환율 상승과 전반적인 자동차 공급 부족, 기아의 상품성 개선에 기반한 판매 믹스 및 인센티브 개선에 기인- 컨퍼런스 콜에서 동사는 반도체 공급 부족이 점진적으로 완화되고 있으나 일부 차질 요인 지속되어 하반기 판매량 회복 속도는 완만할 것으로 예쌍. 다만 타이트한 수급 상황과 개선된 상품성을 기반으로 높은 수준의 수익성 유지할 것으로 전망.\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매수 98.0\n",
      "origin_case2 result :  매도 88.0\n",
      "agument_case1 result :  매수 99.97\n",
      "\n",
      "\n",
      "판가 인상으로 2022년 매출액 추정치 3.1조원으로 상향포스코케미칼에 대한 투자의견 BUY, 목표주가 17만원을 유지한다. 2분기 실적은 양극재 사업의 수익성 개선과 절강포화의 연결실적 편입 효과로 시장 기대치를 크게 상회 했다 음극재 사업은 실적 회복이 지연되었으나 6 월 판가인상으로 하반기 수익성 개선이 기대된다. 메탈가 상승에 따른 양극재 판가 상승과 음극재 가격 인상으로 2022년 매출액 추정치를 상향한다. 본격적인 모멘텀 시점 은 GM 향 양극재 물량 확대가 예상 되는 2023년이다. 하반기로 갈수록 주가는 기대 치를 반영할 것이다.\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매도 80.0\n",
      "origin_case2 result :  매도 98.0\n",
      "agument_case1 result :  매수 99.81\n",
      "\n",
      "\n",
      "2Q22 Review : 양극재 수익성 향상포스코케미칼의 2Q22 연결 실적은 매출 8,032억원(YoY +67%, QoQ +21%), 영업이익 552억원(YoY +55%, QoQ +116%), 지배주주순이익 405억원(YoY +20%, QoQ +12%)으로 컨센서스 상회했다(영업이익 컨센서스 320억원). 1) 배터리 소재 부문(매출 비중 59%)의 경우, 반도체 공급 부족에 따른 전기차 생산 차질로 양극재 및 음극재 출하량은 전분기 대비 소폭 감소했으나, 양극재 부문 판가가 전분기 대비 +40% 상승하며 양극재 합산 매출은 YoY +155%, QoQ +57% 증가했다. 매출 증가율이 가파른 이유는 자회사 절강 화포 양극재 사업이 2분기부터 연결 매출로 반영된 데 따른것으로 이를 제외할 경우 양극재 매출 증가율은 YoY +107%, QoQ +27%다. 양극재 부문 수익성은 판가 상승 과정에서의 래깅 효과 힘입어 전분기 대비 개선된 것으로 추정된다. 2) 철강 비즈니스(매출 비중 41%)의 경우 고로 개수 등 영향으로 전분기 대비 매출 -3% 감소했다. 3) 자회사 피엠씨텍 매출은 침상코크스 판가 상승으로 매출 YoY +75%, QoQ +4% 증가했고, 영업이익률 역시 27.7%로 QoQ +9.9%p 상승했다.\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매수 98.0\n",
      "origin_case2 result :  매도 99.0\n",
      "agument_case1 result :  매수 99.98\n",
      "\n",
      "\n",
      "목표주가 30,000원, 투자의견 매수 유지포스코인터내셔널 목표주가 30,000원, 투자의견 매수 유지한다. 2분기 실적은 최대 실적을 기록하며 시장 컨센서스를 상회했다. 모든 부문에서 유의미한 이익 성장이 나타났다. 철강 부문 피크아웃을 감안하더라도 미얀마 가스전 투자비 회수비율 회복과 Senex Energy 연결 인식으로 하반기에도 이익 성장 흐름은 지속될 것으로 전망된다. 연말로 갈수록 배당 매력도 부각될 여지가 많다고 판단된다. 2022년 예상 PER 3.6배, PBR 0.6배로 극단적인 저평가다.\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매수 99.0\n",
      "origin_case2 result :  매수 99.0\n",
      "agument_case1 result :  매도 99.96\n",
      "\n",
      "\n",
      "2분기에도 2조원 이상의 영업이익 기록이전 잠정실적 공시를 통해 발표한대로 2022년 2분기 POSCO홀딩스의 매출액과 영업이익은 각각 23.0조원(YoY +25.7%, QoQ +8.0%)과 2.1조원(YoY -4.5%, QoQ -8.7%)를 기록했다. 1) 광양 4고로 개보수와 일부 하공정 대수리 영향으로 POSCO의 판매량이 824만톤(YoY -8.5%, QoQ -2.6%)에 그쳤다. 2) 원재료 가격 상승으로 원재료 투입단가가 7.7만원/톤 상승했지만 3) 공격적인 가격인상 정책으로 탄소강 ASP는 당초 예상보다 훨씬 높은 수준인 10.0만원/톤 상승하면서 스프레드가 확대되었다. 4) 동시에 친환경 인프라 관련 국내 계열사들 가운데 포스코에너지는 비수기와 정기대수리 시행으로 전분기대비 이익이 크게 감소했지만 포스코인터내셔널 이익이 크게 증가하면서 상당부분 상쇄시켰다.\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매도 61.0\n",
      "origin_case2 result :  매수 96.0\n",
      "agument_case1 result :  매수 99.98\n",
      "\n",
      "\n",
      "매출액 1,193억원(+32% QoQ), 영업이익 109억원(+30% QoQ) 기록- 당사 예상 매출액 및 영업이익 +10% 수준 상회하는 호실적 기록- 사업부문별 매출액: 양극재 877억원(+57% QoQ), MLCC 필름 316억원(-9% QoQ)- 사업부문별 영업이익: 양극재 74억원(+65% QoQ), MLCC 필름 35억원(-9% QoQ)- 양극재 사업부 판가 상승 및 출하량 증가 지속되며 전분기 대비 큰 폭의 실적 성장- MLCC 필름은 6월부터 고객사 재고조정 시작되며, 전분기 대비 실적 소폭 둔화- 원/달러 환율 상승 효과도 전사 호실적에 주요하게 작용\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매수 96.0\n",
      "origin_case2 result :  매수 99.0\n",
      "agument_case1 result :  매도 96.35\n",
      "\n",
      "\n",
      "2분기 역대급 실적 기록. 지금 피크 아닙니다- 2분기 매출액 1.2조원(+79% QoQ), 영업이익 1,030억원(+151% QoQ) 기록- 신규 라인 가동에 따른 Q(출하량 증가), 판가 상승 + 원/달러 환율 상승 효과\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매도 82.0\n",
      "origin_case2 result :  매도 99.0\n",
      "agument_case1 result :  매수 99.98\n",
      "\n",
      "\n",
      "영업이익 3,206억원: 사상 최고 실적 경신▶ 매출액 11조 699억원(+30% YoY): 트레이딩 철강 및 식량소재 실적 호조-트레이딩 29% YoY: 철강 55% YoY, 제품 단가 상승-에너지 -7% YoY: 미얀마 호조 vs. LNG 트레이딩 부진-투자법인 79% YoY: 구동모터코어, 인니팜, 나라브리 모두 견조▶ 영업이익 3,206억원 (+89% YoY): 컨센서스(2,453억원) 상회-트레이딩 22% YoY: 대두, 합성고무, 무역법인 실적 개선-에너지 219% YoY: 미얀마 가스전 판매단가 8달러/mmBtu 돌파-투자법인 131% YoY: 나라브리 생산량 및 인니팜 마진 예상외 호조\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매수 89.0\n",
      "origin_case2 result :  매수 99.0\n",
      "agument_case1 result :  매도 99.96\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t■ 선박용 엔진밸브 및 형단조품 전문기업으로 매출비중은 엔진부품 42.1%, 형단조품 23.6%, 기타 상품/임가공 34.3% 차지, 동사는 대형 선박 주엔진인 저속엔진 분야 글로벌 원천기술 라이선스인 독일 MAN-ES社와 스위스 WinGD社의 제조 승인을 보유한 업체임■ 동사는 2012년 이후 지속된 조선업 부진에 따른 대규모 손실과 이에 따른 자금난으로 2016년 기업회생절차를 신청, 2018년 최대주주가 한국공작기계에서 금강공업으로 변경되었고, 2019년 3월 기업회생 절차가 종결됨■ 2022년 추정 매출액은 596억원으로 YoY +36.0%, 영업이익은 40억원으로 두배 수준 성장 전망, 외형 증가와 高마진 제품믹스 개선으로 원가율이 낮아져 영업이익률은 6.6%로 전년대비 2.0%p 상승할 전망■ 삼미금속 100% 자회사 편입時 형단조 부문 외형 확대로 사업 포트폴리오 다각화 및 양사간 형단조 부문 영업 시너지 기대, 10월 인수절차가 완료되면 동사는 연결 지배회사, 삼미금속은 100% 완전자회사로 연결 기준 비상장 종속회사로 편입 예정\n",
      "\t\t\t\t\t\t\t\n",
      "==================================================\n",
      "origin_case1 result :  매도 75.0\n",
      "origin_case2 result :  매수 99.0\n",
      "agument_case1 result :  매도 99.91\n",
      "\n",
      "\n",
      "긍정적 환율 효과와 판매 믹스 개선으로 컨센서스 상당 폭 상회- 2분기 영업이익은 3조원으로 컨센서스 상당 폭 상회: 원달러 환율이 큰 폭으로 상승해 긍정적인 환율 효과가 컸고, 지정학적 리스크 등으로 전반적인 자동차 공급 부족이 장기화되면서 현대차의 판매 믹스가 고부가가치 위주로 지속 개선되었기 때문- 컨퍼런스 콜에서 동사는 최근 경기 불확실성이 확대되는 속에서도 국내 미출고물량이 64만대 수준으로 높게 유지되고 있고, 미국과 유렵에서도 대기 고객이 늘어나고 있다고 언급. 또한 SUV, 친환경차 등 고객 수요가 높은 제품 위주로 대응할 계획이라고 밝힘\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매도 81.0\n",
      "origin_case2 result :  매수 87.0\n",
      "agument_case1 result :  매수 98.5\n",
      "\n",
      "\n",
      "2Q22 Preview롯데쇼핑의 2Q22 K-IFRS 연결 기준 매출액은 YoY 1.7% 성장한 3조 9,703억원, 영업이익은 YoY 649.7% 성장한 568억원 추정. 영업이익 YoY +492억원은 컬처웍스 YoY +300억원, 백화점 YoY+202억원, 마트 +220억원 증가, 반면 이커머스 YoY -156억원, 하이마트 -237억원 감소에 따름. 2Q22 국내 백화점 매출액 YoY 9.8% 성장한 7,260억원 추정. 기존점 13% 수준 신장하며 영업이익률 YoY1.8%p 개선된 9.8% 예상. 거리두기 해제(4.18) 후 객수와 객단가 동반성장하며, 해외패션 및 남성/스포츠 중심의 패션 성장세가 전체 성장을 견인. 마트 부문은 2Q22 매출 YoY 4.5% 성장한 1조 4,877억원, 영업적자 -42억원 추정해, 1분기에 이어 온라인 손익 전환(21.8 이커머스 사업부로 이전) 효과 있을 것. 컬처웍스 매출액 YoY 115.7% 성장한 949억원, 영업적자 YoY 300억원 개선된 60억원 예상. 4월 25일부터 영화관 내 팝콘취식 가능해졌으며, 닥터스트레인지/범죄도시2/탑건2 등 대형작이 흥행하면서 롯데시네마의 5,6월 크게 반등한 것으로 추정\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매수 88.0\n",
      "origin_case2 result :  매도 96.0\n",
      "agument_case1 result :  매수 99.94\n",
      "\n",
      "\n",
      "2Q22 Preview신세계인터내셔날의 2Q22 K-IFRS 연결기준 매출액은 YoY 12.7% 성장한 3,841억원, 영업이익은 YoY 30.6% 성장한 346억원 추정. 2Q22 패션부문은 거리두기 해제(4.18) 이후 본격적인 의류 Pent-up 소비 수혜. 해외패션 매출액은 매출액 YoY 24.1% 1,394억원, 영업 이익은 YoY 42.8% 성장한 232억원 추정. OPM YoY 1%p 상승한 16.6% 추정하는데, 견조한 수요와 가격상승 효과에 따름. 국내패션 매출액 YoY 4.5% 성장한 622억원, 영업이익은 흑자전환한 43억원 추정. 자주는 매출 YoY 12% 성장한 696억원, 영업이익 BEP 전환추정. 성장을 견인하는 상품군은 패션(잠옷, 속옷 등) 부문으로, 매출 비중의 43% 수준을 차지. 패션은 생활소품 대비 ASP가 높고, 충성도가 높아 마진에 긍정적임\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매도 71.0\n",
      "origin_case2 result :  매수 92.0\n",
      "agument_case1 result :  매수 99.83\n",
      "\n",
      "\n",
      "2Q22 Preview: 예상보다 빠른 턴어라운드동사의 2Q22 예상 영업이익은 322억원(시장 컨센서스 -91억원)으로 호실적을 전망. DL케미칼의 영업이익은 275억원으로 QoQ +33%(1분기 Kraton 인수관련 비용 186억원 제외 시) 증가할 것으로 예상되는데, 이는 폴리부텐의 시황 호조에 기인. 수출입가격 기준 폴리부텐의 2Q22 평균 가격은 1,982.8달러/톤(QoQ +8.3%)으로 '20년 3분기 이후 8개 분기 연속 증가. Kraton 사업부 역시 예상 대비 호실적을 보일 것으로 추정되는데, 전 사업부에서 1~2분기 연속 가격 상승을 보이고 있기 때문. 케미칼 사업부의 TOFA 가격은 타이트한 수급으로 7개 분기 연속 상승을 보이고 있는데, 1분기 10% 이상의 가격 인상에 이어 지난 6월 1일 7월분 이후 CTO Refinery의 모든 제품에 대해 20% 이상의 가격 인상을 발표. 폴리머 사업부 역시 HSBC 가격을 지난 3월 440달러/톤 인상한 이후, 6월 15일 추가로 330달러/톤 인상을 발표. 이밖에 1분기 정기보수를 완료한 Cariflex의 안정적인 이익 기여, 전력가격 상승에 따른 DL에너지의 계절적 비수기 영향도 제한적일 것으로 전망. 단, 연결자회사 실적 호조에도 불구하고 1) 모노머 시황 악화에 따른 지분법(YNCC, 폴리미래) 이익 저조, 2) 환율 상승에 따른 외환차손(420억원) 발생으로 당기순이익은 적자 전망\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매수 83.0\n",
      "origin_case2 result :  매도 99.0\n",
      "agument_case1 result :  매수 82.82\n",
      "\n",
      "\n",
      "목표주가 52,000원, 투자의견 매수 유지한전KPS 목표주가 52,000원과 투자의견 매수를 유지한다. 2분기 실적은 컨센서스를 하회할 전망이다. 지난 6월 20일 2021년 공공기관 경영평가 결과 발표에서 3년 연속 B 등급으로 결정되어 노무비 증가가 나타날 것으로 예상되며 관련 비용 증가 이슈는 올해를 마지막으로 향후 완화될 전망이다. 증장기적으로 국내 발전Mix 전환에 따른 발전설비 증가에 대한 기대감이 반영될 여지가 있고 연내 발표될 10차 전력 수급기본계획에서 확인이 가능할 전망이다. 2022년 기준 PER 14.3배, PBR 1.4배다.\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매수 96.0\n",
      "origin_case2 result :  매수 99.0\n",
      "agument_case1 result :  매도 97.22\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t■ 테크윙은 반도체 후공정의 핵심 공정에 해당하는 테스트 공정에 필요한 핸들러(Handler) 장비 공급■ 반도체 후공정의 주요 테스트 공정은 2종류(웨이퍼 테스트, 파이널 테스트)였는데 원인을 알 수 없는 불량의 방지와 데이터센터용 반도체의 고사양화 수요에 힘입어 테스트 공정 추가. 비메모리의 경우 실제 사용자 환경과 유사한 조건에서의 시스템 레벨 테스트, 메모리의 경우 SSD(Solid State Drive) 출하 전 별도의 SSD 테스트 자동화 전개. 이와 더불어 교체용 소모품 및 서비스 매출이 테크윙의 실적 성장에 기여■ 2022년 2분기 잠정 연결 매출과 영업이익은 각각 847억원, 224억원을 기록하며 컨센서스 상회. 마이크론 등 해외 반도체 고객사의 설비 투자에 따른 수혜 때문\n",
      "\t\t\t\t\t\t\t\n",
      "==================================================\n",
      "origin_case1 result :  매도 98.0\n",
      "origin_case2 result :  매도 99.0\n",
      "agument_case1 result :  매수 91.36\n",
      "\n",
      "\n",
      "2Q22: 잠시 쉬었다 가겠습니다아프리카TV 2Q22 실적은 매출액 794억원(+22.2% yoy), 영업이익 237억원(+10.5% yoy)을 기록할 전망. 엔데믹 영향으로 2분기 기부경제 매출 쉬었다 가는 국면. 광고는 2분기에도 성장 추이 지속할 전망이나 추정치 소폭 하향. 플랫폼 매출 606억원(+19.7% yoy), 광고 매출은 174억원(+35% yoy)로 각각 추정. 엔데믹 이후 콘텐츠 관련 지출 증가 추정. SKTT1 스트리밍 계약 및 감가상각비 증가로 전반적인 비용 추정치 상향 조정.\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매수 99.0\n",
      "origin_case2 result :  매수 99.0\n",
      "agument_case1 result :  매도 71.48\n",
      "\n",
      "\n",
      "기발표 주주가치 제고 방안 외에 눈여겨봐야 할 투자포인트들LG에 대한 투자의견 매수와 목표주가 125,000원을 유지. 최근 LG는 KOSPI 하락률 대비 주가가 선방하며 초과상승하고 있는데 LG전자와 LG생활건강의 주가가 올해 34.1%와 35.2% 하락하는 등 상장사 지분가치 감소에도 불구하고 5월말 발표된 새로운 주주가치 제고 방안으로 자사주 매입에 따른 수급 개선 기대감과 배당안정성이 커지고 있기 때문. 이외에도 1) 실질 NAV 대비 할인율이 62.3%에 달하는 등 대표적 저평가 종목인데다 2) LG CNS의 IPO 주관사 선정이 마무리되며 2023년 중 상장이 가시화됐다는 점 3) 보유 현금 1.9조원의 구체적인 활용 계획 발표에 따라 국내 기업형 벤처투자회사(CVC) 설립을 통한 투자성과 또한 기대된다는점 등에서 LG에 대한 투자매력이 점차 부각될 것으로 예상\n",
      "\n",
      "==================================================\n",
      "origin_case1 result :  매도 73.0\n",
      "origin_case2 result :  매수 99.0\n",
      "agument_case1 result :  매도 99.95\n",
      "\n",
      "\n",
      "2Q22 Review: 환율과 판가 상승으로 호실적 달성해성디에스의 22년 2분기 매출액은 2,162억원(YoY +36%, QoQ +8%), 영업이익은 541억원(YoY +197%, QoQ +12%)을 기록했다. 하나증권의 추정치대비 각각 7%, 10% 상회했고, 최근 상향된 컨센서스에 부합하는 수준의 실적이다. 우호적인 환율 속에서 1) 패키지기판은 타이트한 수급 상황이 전개되며 견조한 수요가 확인되었고, 2) 전장향 리드프레임은 자동차용 반도체 수급의 일부 완화와 믹스 개선에 의한 가격 상승으로 매출액이 전분기대비 12% 증가했다. 일반 IT제품향 리드프레임은 전반적인 수요 감소에도 공급 부족 상황이 지속되며 전분기대비 소폭의 매출액 증가를 시현했다.\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "want_view_data = merged_inference[[\"article\",\n",
    "                                   \"origin_case1_predictions\", \"origin_case1_pred_rate\",\n",
    "                                   \"origin_case2_predictions\", \"origin_case2_pred_rate\",\n",
    "                                   \"agument_case1_predictions\", \"agument_case1_pred_rate\"]]\n",
    "\n",
    "for idx, (item_idx, item_data) in enumerate(want_view_data.iterrows()):\n",
    "    if idx == 100:\n",
    "        break\n",
    "        \n",
    "    if (item_data[\"origin_case1_predictions\"] != item_data[\"origin_case2_predictions\"]) or \\\n",
    "        (item_data[\"origin_case2_predictions\"] != item_data[\"agument_case1_predictions\"]):\n",
    "        print(\"origin_case1 result : \", item_data[\"origin_case1_predictions\"], item_data[\"origin_case1_pred_rate\"])\n",
    "        print(\"origin_case2 result : \", item_data[\"origin_case2_predictions\"], item_data[\"origin_case2_pred_rate\"])\n",
    "        print(\"agument_case1 result : \", item_data[\"agument_case1_predictions\"], item_data[\"agument_case1_pred_rate\"])\n",
    "        print(item_data[\"article\"])\n",
    "        print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6957c8-12c3-4738-9aa3-85aaebd09d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
