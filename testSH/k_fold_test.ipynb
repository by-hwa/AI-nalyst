{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "960fc129-40a9-4e77-9ffc-66d48fa09ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-09 18:56:38.883533: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoModel, AutoTokenizer, DataCollatorWithPadding\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from datasets import load_dataset\n",
    "from transformers import DataCollatorWithPadding\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed9824c9-6abf-4f13-b6f7-298e95351978",
   "metadata": {},
   "outputs": [],
   "source": [
    "strongbuy = pd.read_csv(\"./data/strongbuy.csv\")\n",
    "sell = pd.read_csv(\"./data/sell.csv\")\n",
    "holddown = pd.read_csv(\"./data/holddown.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77ec7bb6-29c9-4596-bfc9-8fee5e0fe9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>article</th>\n",
       "      <th>length</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>strongbuy51.txt</td>\n",
       "      <td>6월에도 우리나라의 폴리실리콘 수출 가격 상승 국내 정유/석유화학 기업 중 신재생에...</td>\n",
       "      <td>274</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>strongbuy431.txt</td>\n",
       "      <td>이미 건축/주택부문의 영업이익은 분기당 1,500억원 이상 기록이 일반화되었으며, ...</td>\n",
       "      <td>510</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>strongbuy408.txt</td>\n",
       "      <td>1Q16 Preview: 매출 6,053억원, 영업이익 111억원(OPM 1.8%)...</td>\n",
       "      <td>436</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>strongbuy42.txt</td>\n",
       "      <td>두번째로, 대형평형 위주의 공급이었음에도 분양에 성공했다는 것이다. 이번 분양은 전...</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>strongbuy416.txt</td>\n",
       "      <td>연말 까지 200개 점포가 중간관리제로 전환될 경우 약 58억원 수준의 인건비를 절...</td>\n",
       "      <td>424</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>strongbuy476.txt</td>\n",
       "      <td> 투자의견 STRONG BUY, 목표주가 146,000원 유지 한국항공우주 투자의...</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>strongbuy133.txt</td>\n",
       "      <td>디스플레이 업체별 양극화 더 뚜렷해질 것 글로벌 패널업체들의 10.5세대 TFT 투...</td>\n",
       "      <td>584</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2747</th>\n",
       "      <td>holddown111.txt</td>\n",
       "      <td>탑라인 성장 전략 긍정적이지만, 제작비 증가는 수익성 부담 회사는 올해 가이던스로 ...</td>\n",
       "      <td>603</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>strongbuy443.txt</td>\n",
       "      <td>외형성장보다 수익성 우선 동사는 무분별한 저가수주를 회피하며 수익성 향상을 추구한다...</td>\n",
       "      <td>485</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2749</th>\n",
       "      <td>strongbuy23.txt</td>\n",
       "      <td>▶본사 : 드롭액은 8,538억원(+3% YoY)으로 증가했고, 홀드율은 10.2%...</td>\n",
       "      <td>352</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2750 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename                                            article  \\\n",
       "0      strongbuy51.txt  6월에도 우리나라의 폴리실리콘 수출 가격 상승 국내 정유/석유화학 기업 중 신재생에...   \n",
       "1     strongbuy431.txt  이미 건축/주택부문의 영업이익은 분기당 1,500억원 이상 기록이 일반화되었으며, ...   \n",
       "2     strongbuy408.txt  1Q16 Preview: 매출 6,053억원, 영업이익 111억원(OPM 1.8%)...   \n",
       "3      strongbuy42.txt  두번째로, 대형평형 위주의 공급이었음에도 분양에 성공했다는 것이다. 이번 분양은 전...   \n",
       "4     strongbuy416.txt  연말 까지 200개 점포가 중간관리제로 전환될 경우 약 58억원 수준의 인건비를 절...   \n",
       "...                ...                                                ...   \n",
       "2745  strongbuy476.txt   투자의견 STRONG BUY, 목표주가 146,000원 유지 한국항공우주 투자의...   \n",
       "2746  strongbuy133.txt  디스플레이 업체별 양극화 더 뚜렷해질 것 글로벌 패널업체들의 10.5세대 TFT 투...   \n",
       "2747   holddown111.txt  탑라인 성장 전략 긍정적이지만, 제작비 증가는 수익성 부담 회사는 올해 가이던스로 ...   \n",
       "2748  strongbuy443.txt  외형성장보다 수익성 우선 동사는 무분별한 저가수주를 회피하며 수익성 향상을 추구한다...   \n",
       "2749   strongbuy23.txt  ▶본사 : 드롭액은 8,538억원(+3% YoY)으로 증가했고, 홀드율은 10.2%...   \n",
       "\n",
       "      length  label  \n",
       "0        274      1  \n",
       "1        510      1  \n",
       "2        436      1  \n",
       "3        205      1  \n",
       "4        424      1  \n",
       "...      ...    ...  \n",
       "2745     512      1  \n",
       "2746     584      1  \n",
       "2747     603      0  \n",
       "2748     485      1  \n",
       "2749     352      1  \n",
       "\n",
       "[2750 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sell = pd.concat([sell, holddown])\n",
    "all_data = pd.concat([strongbuy, all_sell])\n",
    "all_data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aecb10bc-3cb6-4517-923a-c62a8ec3bdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 : 0.6799\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(strongbuy)/len(strongbuy)} : {(len(sell) + len(holddown)) / len(strongbuy):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6a91312-4e94-4945-a3d2-4390721820b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(all_data, test_size=0.2, random_state=42, stratify=all_data[[\"label\"]])\n",
    "\n",
    "test_data[\"labels\"] = test_data[\"label\"]\n",
    "test_data = test_data.drop(labels=[\"filename\", \"length\", \"label\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2cb32b5-ba67-4b47-9dd0-7bcfc052630d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_length = 5\n",
    "X = train_data.drop(labels=[\"filename\", \"length\", \"label\"], axis=1)\n",
    "y = train_data[\"label\"]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=fold_length, shuffle=True, random_state=42)\n",
    "fold_dataframe = list()\n",
    "\n",
    "for fold_number, (train, valid) in enumerate(skf.split(X, y), 1):\n",
    "    X_train, X_valid = X.iloc[train], X.iloc[valid]\n",
    "    y_train, y_valid = y.iloc[train], y.iloc[valid]\n",
    "    \n",
    "    fold_train = X_train.loc[:]\n",
    "    fold_train[\"labels\"] = y_train\n",
    "    \n",
    "    fold_valid = X_valid.loc[:]\n",
    "    fold_valid[\"labels\"] = y_valid\n",
    "    \n",
    "    fold_train.to_csv(f\"./data/train_data_fold{fold_number}.csv\", index=False)\n",
    "    fold_valid.to_csv(f\"./data/valid_data_fold{fold_number}.csv\", index=False)\n",
    "\n",
    "test_data.to_csv(f\"./data/test_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80934118-b730-40a7-a091-25b34c4698fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/kb-albert-char-base-v2 were not used when initializing AlbertModel: ['predictions.bias', 'predictions.decoder.weight', 'predictions.dense.bias', 'predictions.dense.weight', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.decoder.bias', 'sop_classifier.classifier.bias', 'sop_classifier.classifier.weight']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "kb_albert_model_path = \"./model/kb-albert-char-base-v2\"\n",
    "albert = AutoModel.from_pretrained(kb_albert_model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(kb_albert_model_path)\n",
    "\n",
    "tokenizer.truncation_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da9885a5-7c0f-4ba9-a4ac-27439beed01f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-d03887d24e8e1d37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-d03887d24e8e1d37/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc87c2829c014461a0edaa0574ae2a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd3db52e89a421595aef59f79339b2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-d03887d24e8e1d37/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58694edaf584426daf56ce596a591f76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-d9ec5cbbb5b92d44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-d9ec5cbbb5b92d44/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ae92ddee3e499a9e2d0e83cd125ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3b0fd3556bf45ed908b092429dbac1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-d9ec5cbbb5b92d44/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7104f91af78a4f75afe690cc0c8d76e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ddba5c7e37749dbbf37a957723571af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1760 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e9227756914fdf9b71f98b8678f028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/440 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-6aee71a58785c2fe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-6aee71a58785c2fe/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63492b3ee1e84585a8a00edc684779eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa5b467b1c9345ac8d887315ad8ed67d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-6aee71a58785c2fe/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6eb9c7e37ce44f8a740b22eda48c008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-65f6f46fb276cda8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-65f6f46fb276cda8/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7cc627d8d443e4bab3e241f537af70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e86ac3380f14a769acf4b29b9bd0eeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-65f6f46fb276cda8/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42b97e6fd9bb4bf1b44185bb1afabc9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1821b5dfe606432592f7dbf3b6c5373b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1760 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9160c17b12f4a7c88779ee35c3759da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/440 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-8719a7e61d9e3e9c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-8719a7e61d9e3e9c/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e106ba0d5db4e8799fc2ea077bf50f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "044d50684c6b4bd98b2cd14f2b680368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-8719a7e61d9e3e9c/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0125c64ceca4aa7a9d50763895eeaa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-0e83855deb663a30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-0e83855deb663a30/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ea4b4acb6247428458fcef118f332b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0869089401bc4e0c8b541a98230426ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-0e83855deb663a30/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2ce3e8b345e48c8a04cd98c0481fcbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97fea9ae90454ddfa3f337080fbba1bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1760 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1413586cf778464389790d0809bd8c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/440 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-705c6f06df2f1b31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-705c6f06df2f1b31/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c3cbd1f9a14457bf0b7d8feb178e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe6997957443410c8078f1c293331dbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-705c6f06df2f1b31/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0076ad703e5b4c23ba17c4b0747f9520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-c2a55a9a1bc3aa3b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-c2a55a9a1bc3aa3b/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e4d580c96b448ac9bda4543cf84f987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d0dd5ef474437fa5345d66a2dbcdee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-c2a55a9a1bc3aa3b/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77039c505bdb437ca0e5085848371a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78971d60260f4e4fb8358aab49018cf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1760 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a38aa3d2e604e8c8e12289f790f855a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/440 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-7c9c1574f767c5e5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-7c9c1574f767c5e5/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a16ce3f3a344a1aa1c7ee40525bda7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f250c8951ab46ce93a0ae63e34e11ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-7c9c1574f767c5e5/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce9dde390d18450a9d7e5608cd94e2a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-a4b0b5705573185b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-a4b0b5705573185b/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a969351bcd64f91a8b31fc5346cbba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e34e77a0fd43f981adaff92191cbc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-a4b0b5705573185b/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faecc04b10c343239bc75a7f6ab32bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b95477c98845cb8d4a9ae115ef59f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1760 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8130b579d08d45069ae99a6029afdb12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/440 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-8750c0716a3a9f42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-8750c0716a3a9f42/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57aecabd7e6248188caffea16a272cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ab7fef08bcc4fcbba2291d36f492b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-8750c0716a3a9f42/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b42144045744c22884a0073e65d04c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad117f6fd3c04fd2b4ee586c64278174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LEN = 512\n",
    "\n",
    "def tokenized_fn(data):\n",
    "    outputs = tokenizer(data[\"article\"], padding=\"max_length\", max_length=MAX_LEN, truncation=True)\n",
    "    outputs[\"labels\"] = data[\"labels\"]\n",
    "    return outputs\n",
    "\n",
    "dataset_list = list()\n",
    "for fold_number in range(1, fold_length+1):\n",
    "    train_dataset = load_dataset(\"csv\", data_files=f\"./data/train_data_fold{fold_number}.csv\")[\"train\"]\n",
    "    valid_dataset = load_dataset(\"csv\", data_files=f\"./data/valid_data_fold{fold_number}.csv\")[\"train\"]\n",
    "\n",
    "    train_dataset = train_dataset.map(tokenized_fn, remove_columns=[\"article\"])\n",
    "    valid_dataset = valid_dataset.map(tokenized_fn, remove_columns=[\"article\"])\n",
    "    \n",
    "    dataset_list.append([train_dataset, valid_dataset])\n",
    "\n",
    "test_dataset = load_dataset(\"csv\", data_files=f\"./data/test_data.csv\")[\"train\"]\n",
    "test_dataset = test_dataset.map(tokenized_fn, remove_columns=[\"article\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15ac9d0d-6d71-4abb-89cc-5edede64a91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "dataloader_list = list()\n",
    "for train_fold, valid_fold in dataset_list:\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_fold,\n",
    "        sampler = torch.utils.data.RandomSampler(train_fold),\n",
    "        batch_size = batch_size,\n",
    "        collate_fn = data_collator,\n",
    "    )\n",
    "\n",
    "    validation_dataloader = torch.utils.data.DataLoader(\n",
    "        valid_fold,\n",
    "        sampler = torch.utils.data.SequentialSampler(valid_fold),\n",
    "        batch_size = batch_size,\n",
    "        collate_fn = data_collator,\n",
    "    )\n",
    "    \n",
    "    dataloader_list.append([train_dataloader, validation_dataloader])\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    sampler = torch.utils.data.SequentialSampler(test_dataset),\n",
    "    batch_size = batch_size,\n",
    "    collate_fn = data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96f5859f-689a-46a7-b2a0-7e583ef676b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(0.25)\n",
    "        self.out_proj = torch.nn.Linear(768, 2)\n",
    "    \n",
    "    def forward(self, features):\n",
    "        # 보통 분류기에선 start 토큰에 분류 결과를 담음\n",
    "        x = features[:, 0, :]    # take <s> token (equiv. to [CLS])\n",
    "        x = x.reshape(-1, x.size(-1))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.out_proj(x)\n",
    "        return x\n",
    "\n",
    "class AInalyst(torch.nn.Module):\n",
    "    def __init__(self, pretrained_model):\n",
    "        super(AInalyst, self).__init__()\n",
    "        self.pretrained = pretrained_model\n",
    "        self.classifier = ClassificationHead()\n",
    "    \n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None):\n",
    "        outputs = self.pretrained(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            # labels=labels\n",
    "        )\n",
    "        self.labels = labels\n",
    "        logits = self.classifier(outputs[\"last_hidden_state\"])\n",
    "        # prob = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        \n",
    "        if labels is not None:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits, labels)\n",
    "            return logits, loss\n",
    "        else:\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95223fe8-8c47-4d7f-8107-8231fe60127e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bf1f4ce-9a10-492a-b6cc-2736d78e669a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = AInalyst(pretrained_model=albert)\n",
    "model.to(device)\n",
    "model = torch.nn.DataParallel(model)\n",
    "isParallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a8a5431-14ec-4895-b3eb-58ba0e6d08ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0582000-da1b-4227-8aba-5eba428bab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05969563-c25e-4f37-8a30-90557db0f0cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ Epoch 1/5 ============\n",
      "Training...\n",
      "===== Epoch 1/5 - Fold 1/5 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piai/anaconda3/envs/iml/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Average training loss: 0.60353\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 0.80804\n",
      "===== Epoch 1/5 - Fold 2/5 =====\n",
      "\n",
      " Average training loss: 0.32967\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 0.91295\n",
      "===== Epoch 1/5 - Fold 3/5 =====\n",
      "\n",
      " Average training loss: 0.17486\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 0.96652\n",
      "===== Epoch 1/5 - Fold 4/5 =====\n",
      "\n",
      " Average training loss: 0.08151\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 0.98438\n",
      "===== Epoch 1/5 - Fold 5/5 =====\n",
      "\n",
      " Average training loss: 0.04464\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 0.99777\n",
      "===== Epoch 1/5 - Test =====\n",
      "\n",
      "Running Test...\n",
      "\n",
      " Test Accuracy: 0.92202\n",
      "\n",
      "============ Epoch 2/5 ============\n",
      "Training...\n",
      "===== Epoch 2/5 - Fold 1/5 =====\n",
      "\n",
      " Average training loss: 0.01512\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 2/5 - Fold 2/5 =====\n",
      "\n",
      " Average training loss: 0.00634\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 2/5 - Fold 3/5 =====\n",
      "\n",
      " Average training loss: 0.00425\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 2/5 - Fold 4/5 =====\n",
      "\n",
      " Average training loss: 0.00303\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 2/5 - Fold 5/5 =====\n",
      "\n",
      " Average training loss: 0.00241\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 2/5 - Test =====\n",
      "\n",
      "Running Test...\n",
      "\n",
      " Test Accuracy: 0.93571\n",
      "\n",
      "============ Epoch 3/5 ============\n",
      "Training...\n",
      "===== Epoch 3/5 - Fold 1/5 =====\n",
      "\n",
      " Average training loss: 0.00199\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 3/5 - Fold 2/5 =====\n",
      "\n",
      " Average training loss: 0.00167\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 3/5 - Fold 3/5 =====\n",
      "\n",
      " Average training loss: 0.00142\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 3/5 - Fold 4/5 =====\n",
      "\n",
      " Average training loss: 0.00120\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 3/5 - Fold 5/5 =====\n",
      "\n",
      " Average training loss: 0.00109\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 3/5 - Test =====\n",
      "\n",
      "Running Test...\n",
      "\n",
      " Test Accuracy: 0.93393\n",
      "\n",
      "============ Epoch 4/5 ============\n",
      "Training...\n",
      "===== Epoch 4/5 - Fold 1/5 =====\n",
      "\n",
      " Average training loss: 0.00094\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 4/5 - Fold 2/5 =====\n",
      "\n",
      " Average training loss: 0.00082\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 4/5 - Fold 3/5 =====\n",
      "\n",
      " Average training loss: 0.00074\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 4/5 - Fold 4/5 =====\n",
      "\n",
      " Average training loss: 0.00064\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 4/5 - Fold 5/5 =====\n",
      "\n",
      " Average training loss: 0.00061\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 4/5 - Test =====\n",
      "\n",
      "Running Test...\n",
      "\n",
      " Test Accuracy: 0.93393\n",
      "\n",
      "============ Epoch 5/5 ============\n",
      "Training...\n",
      "===== Epoch 5/5 - Fold 1/5 =====\n",
      "\n",
      " Average training loss: 0.00056\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 5/5 - Fold 2/5 =====\n",
      "\n",
      " Average training loss: 0.00050\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 5/5 - Fold 3/5 =====\n",
      "\n",
      " Average training loss: 0.00046\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 5/5 - Fold 4/5 =====\n",
      "\n",
      " Average training loss: 0.00041\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 5/5 - Fold 5/5 =====\n",
      "\n",
      " Average training loss: 0.00040\n",
      "\n",
      "Running Validation...\n",
      "\n",
      " Valid Accuracy: 1.00000\n",
      "===== Epoch 5/5 - Test =====\n",
      "\n",
      "Running Test...\n",
      "\n",
      " Test Accuracy: 0.93214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"============ Epoch {epoch+1}/{epochs} ============\")\n",
    "    print(\"Training...\")\n",
    "    \n",
    "    for fold_number, (train_dataloader, validation_dataloader) in enumerate(dataloader_list, 1):\n",
    "        print(f\"===== Epoch {epoch+1}/{epochs} - Fold {fold_number}/{fold_length} =====\")\n",
    "        total_train_loss = 0\n",
    "        model.train()\n",
    "\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            batch_input_ids = batch[\"input_ids\"].to(device)\n",
    "            batch_attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            batch_labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            model.zero_grad()\n",
    "\n",
    "            logits, loss = model(\n",
    "                input_ids = batch_input_ids,\n",
    "                attention_mask = batch_attention_mask,\n",
    "                labels = batch_labels,\n",
    "            )\n",
    "\n",
    "            if isParallel:\n",
    "                loss = loss.mean()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # if step % 1000 == 0 and not step == 0:\n",
    "            #     print(\"step : {:>5,} of {:>5,} loss: {:.5f}\".format(step, len(train_dataloader), loss.item()))\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "        print()\n",
    "        print(\" Average training loss: {0:.5f}\".format(avg_train_loss))\n",
    "\n",
    "        # Validation\n",
    "        print()\n",
    "        print(\"Running Validation...\")\n",
    "\n",
    "        model.eval()\n",
    "        total_eval_accuracy = 0\n",
    "        total_eval_loss = 0\n",
    "        nb_eval_steps = 0\n",
    "\n",
    "        for step, batch in enumerate(validation_dataloader):\n",
    "            batch_input_ids = batch[\"input_ids\"].to(device)\n",
    "            batch_attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            batch_labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits, loss = model(\n",
    "                    input_ids = batch_input_ids,\n",
    "                    attention_mask = batch_attention_mask,\n",
    "                    labels = batch_labels,\n",
    "                )\n",
    "\n",
    "                if isParallel:\n",
    "                    loss = loss.mean()\n",
    "\n",
    "                total_eval_loss += loss.item()\n",
    "                logits = logits.detach().cpu().numpy()\n",
    "                label_ids = batch_labels.to(\"cpu\").numpy()\n",
    "                total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "        avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "        print()\n",
    "        print(\" Valid Accuracy: {0:.5f}\".format(avg_val_accuracy))\n",
    "    \n",
    "    # Test\n",
    "    print(f\"===== Epoch {epoch+1}/{epochs} - Test =====\")\n",
    "    print()\n",
    "    print(\"Running Test...\")\n",
    "\n",
    "    model.eval()\n",
    "    total_test_accuracy = 0\n",
    "    total_test_loss = 0\n",
    "    nb_test_steps = 0\n",
    "    \n",
    "    for step, batch in enumerate(test_dataloader):\n",
    "        batch_input_ids = batch[\"input_ids\"].to(device)\n",
    "        batch_attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        batch_labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits, loss = model(\n",
    "                input_ids = batch_input_ids,\n",
    "                attention_mask = batch_attention_mask,\n",
    "                labels = batch_labels,\n",
    "            )\n",
    "\n",
    "            if isParallel:\n",
    "                loss = loss.mean()\n",
    "\n",
    "            total_test_loss += loss.item()\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = batch_labels.to(\"cpu\").numpy()\n",
    "            total_test_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "    avg_test_accuracy = total_test_accuracy / len(test_dataloader)\n",
    "    print()\n",
    "    print(\" Test Accuracy: {0:.5f}\".format(avg_test_accuracy))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06109df5-d5e7-421d-9012-04578ce923a5",
   "metadata": {},
   "source": [
    "## Model Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ba39b1e-c0a9-4510-9d55-8e42d5f11138",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./model/kbalbert_epoch5_fold5.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8dfe35-2c5f-41e8-bbb7-8ff2717ca604",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fec8ff9-0a6d-4d56-8d03-27f571a6da59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model = AInalyst(pretrained_model=albert)\n",
    "load_model.to(device)\n",
    "load_model = torch.nn.DataParallel(load_model)\n",
    "load_model.load_state_dict(torch.load(\"./model/kbalbert_epoch5_fold5.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60689f07-5a60-4029-875c-540b997341e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-68bfb0a5382dece9\n",
      "Reusing dataset csv (/home/piai/.cache/huggingface/datasets/csv/default-68bfb0a5382dece9/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3633a1e611724588838a33869571166f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/piai/.cache/huggingface/datasets/csv/default-68bfb0a5382dece9/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-0c67678741f0cfd7.arrow\n"
     ]
    }
   ],
   "source": [
    "def inference_tokenized_fn(data):\n",
    "    outputs = tokenizer(data[\"article\"], padding=\"max_length\", max_length=MAX_LEN, truncation=True)\n",
    "    return outputs\n",
    "\n",
    "inference_dataset = load_dataset(\"csv\", data_files=f\"./data/inference_data.csv\")[\"train\"]\n",
    "inference_dataset = inference_dataset.map(inference_tokenized_fn,\n",
    "                                          remove_columns=[\"Unnamed: 0\", \"company\", \"title\", \"opinion\", \"firm\", \"date\", \"article\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5dd4a261-c965-4c23-b541-100dcd01f2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_dataloader = torch.utils.data.DataLoader(\n",
    "    inference_dataset,\n",
    "    sampler = torch.utils.data.SequentialSampler(inference_dataset),\n",
    "    batch_size = 1,\n",
    "    collate_fn = data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5eaf7e1-56fc-4c9e-ac95-2d7dd36d21fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inference: 100%|██████████████████████████| 50083/50083 [19:29<00:00, 42.81it/s]\n"
     ]
    }
   ],
   "source": [
    "load_model.eval()\n",
    "\n",
    "probabilities = list()\n",
    "predictions = list()\n",
    "\n",
    "for step, batch in enumerate(tqdm(inference_dataloader, desc=\"inference\", mininterval=0.1)):\n",
    "    batch_input_ids = batch[\"input_ids\"].to(device)\n",
    "    batch_attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = load_model(\n",
    "            input_ids = batch_input_ids,\n",
    "            attention_mask = batch_attention_mask,\n",
    "        )\n",
    "        \n",
    "        prob = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        predict = torch.argmax(prob, axis=1)\n",
    "        \n",
    "        prob = np.trunc(np.max(prob.detach().cpu().numpy(), axis=1) * 100)\n",
    "        predict = predict.detach().cpu().numpy()\n",
    "        \n",
    "        probabilities.append(prob[0])\n",
    "        predictions.append(predict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83876235-0f08-43ae-87eb-47af4e164747",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_dataframe = pd.read_csv(\"./data/inference_data.csv\")\n",
    "\n",
    "convert_predictions = list(map(lambda x: \"매수\" if x == 1 else \"매도\", predictions))\n",
    "inference_dataframe = inference_dataframe.drop(labels=\"Unnamed: 0\", axis=1)\n",
    "inference_dataframe[\"predictions\"] = convert_predictions\n",
    "inference_dataframe[\"pred_rate\"] = probabilities\n",
    "inference_dataframe.to_csv(f\"./data/convert_inference_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "803aa4a6-e9eb-4304-b7e1-ba8923c32777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "매수    32975\n",
       "매도    17108\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_dataframe[\"predictions\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d9dad7-797b-4998-a41f-14b8418310d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
