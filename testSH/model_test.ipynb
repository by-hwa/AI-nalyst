{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e25b0db9-48e3-4668-9240-48fa1c23013e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-03 18:52:54.861866: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModel, AutoTokenizer, DataCollatorWithPadding\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d273658d-d394-4fcf-873d-818d0cc21129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "strongbuys = list()\n",
    "holddowns = list()\n",
    "\n",
    "for idx in range(332, 415):\n",
    "    try:\n",
    "        file = open(f\"./data/strongbuy/strongbuy{idx}.txt\", \"r\")\n",
    "        strings = file.readlines()\n",
    "        strings = \"\".join(strings)\n",
    "        string_list = strings.split(\"!@#$\")\n",
    "        for string in string_list:\n",
    "            strongbuys.append(string)\n",
    "        file.close()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for idx in range(212, 265):\n",
    "    try:\n",
    "        file = open(f\"./data/holddown/holddown{idx}.txt\", \"r\")\n",
    "        strings = file.readlines()\n",
    "        strings = \"\".join(strings)\n",
    "        string_list = strings.split(\"!@#$\")\n",
    "        for string in string_list:\n",
    "            holddowns.append(string)\n",
    "        file.close()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(len(strongbuys))\n",
    "print(len(holddowns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab5718a0-da6c-48b7-8ef9-43417d49f559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns=(\"document\", \"labels\"))\n",
    "\n",
    "for doc in strongbuys: df = df.append({\"document\":doc, \"labels\":1}, ignore_index=True)\n",
    "for doc in holddowns:  df = df.append({\"document\":doc, \"labels\":0}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c16b5f2d-e05e-411b-9445-691f549421ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "투자의견 Strong Buy, 목표주가 50,000원 유지\n",
      "1Q16 실적 기대치 상회, 고객사 내 점유율 확대 효과\n",
      "2Q16 영업이익 146억원으로 성장세 지속\n",
      "LG디스플레이 내 TV패널 점유율 확대, OLED패널 독점 공급에 따른 성장세 지속 전망\n",
      "1Q16 매출액 1,590억원(+83% YoY), 영업이익 149억원(+52% YoY) , 기대치 상회\n",
      "당사 예상과 같이 고객사 내 점유율 상승과 이에 따른 수익성 개선 효과가 나타났음\n",
      "스마트폰과 테블릿PC 내 점유율 확대로 COG 부문의 실적 호조\n",
      "TV패널 내 점유율 확대로 COF, TCON, PMIC의 실적 호조\n",
      "판관비 내 일회성 비용(제품손실보증비 15억원) 제외하면 실질 영업이익은 165억원 수준\n",
      "2Q16 매출액 1,548억원(+24% YoY), 영업이익 146억원(+17% YoY) , 성장 지속 전망\n",
      "스마트폰과 테블릿PC 수요 감소로 COG부문의 실적 감소 예상되나,\n",
      "TV패널 내 점유율 확대가 이를 상쇄하며 실적 성장세 지속시킬 전망\n",
      "--------------------\n",
      "투자의견 Strong Buy, 목표주가 50,000원 유지 1Q16 실적 기대치 상회, 고객사 내 점유율 확대 효과 2Q16 영업이익 146억원으로 성장세 지속 LG디스플레이 내 TV패널 점유율 확대, OLED패널 독점 공급에 따른 성장세 지속 전망 1Q16 매출액 1,590억원(+83% YoY), 영업이익 149억원(+52% YoY) , 기대치 상회 당사 예상과 같이 고객사 내 점유율 상승과 이에 따른 수익성 개선 효과가 나타났음 스마트폰과 테블릿PC 내 점유율 확대로 COG 부문의 실적 호조 TV패널 내 점유율 확대로 COF, TCON, PMIC의 실적 호조 판관비 내 일회성 비용(제품손실보증비 15억원) 제외하면 실질 영업이익은 165억원 수준 2Q16 매출액 1,548억원(+24% YoY), 영업이익 146억원(+17% YoY) , 성장 지속 전망 스마트폰과 테블릿PC 수요 감소로 COG부문의 실적 감소 예상되나, TV패널 내 점유율 확대가 이를 상쇄하며 실적 성장세 지속시킬 전망\n",
      "========================================\n",
      "▶ Highlight\n",
      "2Q16 어닝쇼크 때와는 정반대의 어닝서프라이즈. 진에어 홀로 서프라이즈를\n",
      "만들어냄. 진에어 영업이익 401억원(OPM 18.3%). 국내선과 국제선 yield가 각각\n",
      "19%, 14% 상승. 유가약세 구간에서 상상하기 어려운 단가 상승폭\n",
      "▶ Pitch\n",
      "- 진에어의 yield 상승에서 강력한 가격결정권을 확인함. 유가, 환율 상승을\n",
      "가정하고 있지만 Capa 증가 속에 현 수준의 이익 규모는 지킬 수 있다고 판단함\n",
      "- 진에어 16E 영업이익 628억원, 순이익 492억원. 시총 1조원으로 평가해도 무방\n",
      "- 당사가 산정하는 NAV 방식의 TP 2.5만원엔 대한항공 31% 지분가치를 아예\n",
      "반영하지 않음. 즉, 기본적으로 크게 저평가 되어있기 때문에 대한항공의 유상증자\n",
      "혹은 일감몰아주기 규제 가능성 때문에 주가가 묶여있을 필요는 없다는 판단\n",
      "- 최근 주가약세로 상승여력이 확대되어 투자의견을 Strong Buy로 상향조정\n",
      "\n",
      "--------------------\n",
      "▶ Highlight 2Q16 어닝쇼크 때와는 정반대의 어닝서프라이즈. 진에어 홀로 서프라이즈를 만들어냄. 진에어 영업이익 401억원(OPM 18.3%). 국내선과 국제선 yield가 각각 19%, 14% 상승. 유가약세 구간에서 상상하기 어려운 단가 상승폭 ▶ Pitch - 진에어의 yield 상승에서 강력한 가격결정권을 확인함. 유가, 환율 상승을 가정하고 있지만 Capa 증가 속에 현 수준의 이익 규모는 지킬 수 있다고 판단함 - 진에어 16E 영업이익 628억원, 순이익 492억원. 시총 1조원으로 평가해도 무방 - 당사가 산정하는 NAV 방식의 TP 2.5만원엔 대한항공 31% 지분가치를 아예 반영하지 않음. 즉, 기본적으로 크게 저평가 되어있기 때문에 대한항공의 유상증자 혹은 일감몰아주기 규제 가능성 때문에 주가가 묶여있을 필요는 없다는 판단 - 최근 주가약세로 상승여력이 확대되어 투자의견을 Strong Buy로 상향조정 \n",
      "========================================\n",
      "\n",
      "▶ In detail\n",
      "- 진에어: 매출액 2193억원(YoY +48%, QoQ +12%), 영업이익 402억원(YoY +195%,\n",
      "QoQ 흑자전환), 영업이익률 18.3%(YoY +7.2%pt, QoQ +23.3%pt)\n",
      "- 실적 호조의 원인은 높은 탑승률에서 기인하는 높은 yield\n",
      "- 국제선: ASK 81% 증가, L/F 86.3%로 YoY 3.2%pt 상승. Yield YoY 14% 상승\n",
      "- 하와이노선 L/F가 81%, 하와이를 제외한 여타 국제노선이 87%를 기록한 것으로\n",
      "추정. 계절적 편차가 심한 하와이노선 L/F 크게 개선(1Q16 62.9%, 2Q16 49.1%)\n",
      "- 국내선은 3Q15부터 Yield가 YoY 하락세를 보이다 금번 분기 무려 19% 상승\n",
      "- P와 Q가 9%, 67% 급등하며 영업이익률 상승\n",
      "- 유류비는 운항증가로 452억원(YoY +57%). 그러나, 매출액대비 유류비 비중은\n",
      "20.7%로 YoY 2.8% 하락\n",
      "- 진에어의 분기별 실적 변동성은 예견했지만 2Q16 어닝쇼크 이후 펀더멘털을\n",
      "지나치게 낮게 평가하지 않았나 하는 반성\n",
      "- 자회사 별 실적은 Fig.01 참조\n",
      "- 대한항공, 한진에서 지분법이익이 1,395억원 발생했으나 한진해운 상표권 관련\n",
      "무형자산 1,855억원 감액손실 발생. 본사(별도)는 38억원의 대손을 인식\n",
      "--------------------\n",
      " ▶ In detail - 진에어: 매출액 2193억원(YoY +48%, QoQ +12%), 영업이익 402억원(YoY +195%, QoQ 흑자전환), 영업이익률 18.3%(YoY +7.2%pt, QoQ +23.3%pt) - 실적 호조의 원인은 높은 탑승률에서 기인하는 높은 yield - 국제선: ASK 81% 증가, L/F 86.3%로 YoY 3.2%pt 상승. Yield YoY 14% 상승 - 하와이노선 L/F가 81%, 하와이를 제외한 여타 국제노선이 87%를 기록한 것으로 추정. 계절적 편차가 심한 하와이노선 L/F 크게 개선(1Q16 62.9%, 2Q16 49.1%) - 국내선은 3Q15부터 Yield가 YoY 하락세를 보이다 금번 분기 무려 19% 상승 - P와 Q가 9%, 67% 급등하며 영업이익률 상승 - 유류비는 운항증가로 452억원(YoY +57%). 그러나, 매출액대비 유류비 비중은 20.7%로 YoY 2.8% 하락 - 진에어의 분기별 실적 변동성은 예견했지만 2Q16 어닝쇼크 이후 펀더멘털을 지나치게 낮게 평가하지 않았나 하는 반성 - 자회사 별 실적은 Fig.01 참조 - 대한항공, 한진에서 지분법이익이 1,395억원 발생했으나 한진해운 상표권 관련 무형자산 1,855억원 감액손실 발생. 본사(별도)는 38억원의 대손을 인식\n",
      "========================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>투자의견 Strong Buy, 목표주가 50,000원 유지 1Q16 실적 기대치 상...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>▶ Highlight 2Q16 어닝쇼크 때와는 정반대의 어닝서프라이즈. 진에어 홀로...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>▶ In detail - 진에어: 매출액 2193억원(YoY +48%, QoQ +...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>숨겨진진주 3Q14 Review : 매출 3469 억원 , 영업이익 428억원 (O...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 4Q14 Preview: 매출 3,554 억원 영업이익 438억원 (OPM 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>실적 해석 및 시사점 견조한 실적 개선세 지속: 1Q 양호한 실적은 1) RC값 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>한국항공우주 (047810) 코로나19 여파로 상반기는 저공비행 투자의견 시장수익률...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>1Q21 Review 코로나19 여파로 기체부품, 완제기 수출의 매출 감소 - 1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>롯데케미칼 011170 회복을 논하기에는 이른 시점  4Q19 영업이익 1,426...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>중국 우한폐렴 확산: 1H20 위축→2H20 회복 / PE 수요 전망치 하향 조정...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>279 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              document labels\n",
       "0    투자의견 Strong Buy, 목표주가 50,000원 유지 1Q16 실적 기대치 상...      1\n",
       "1    ▶ Highlight 2Q16 어닝쇼크 때와는 정반대의 어닝서프라이즈. 진에어 홀로...      1\n",
       "2     ▶ In detail - 진에어: 매출액 2193억원(YoY +48%, QoQ +...      1\n",
       "3    숨겨진진주 3Q14 Review : 매출 3469 억원 , 영업이익 428억원 (O...      1\n",
       "4      4Q14 Preview: 매출 3,554 억원 영업이익 438억원 (OPM 1...      1\n",
       "..                                                 ...    ...\n",
       "274   실적 해석 및 시사점 견조한 실적 개선세 지속: 1Q 양호한 실적은 1) RC값 ...      0\n",
       "275  한국항공우주 (047810) 코로나19 여파로 상반기는 저공비행 투자의견 시장수익률...      0\n",
       "276   1Q21 Review 코로나19 여파로 기체부품, 완제기 수출의 매출 감소 - 1...      0\n",
       "277  롯데케미칼 011170 회복을 논하기에는 이른 시점  4Q19 영업이익 1,426...      0\n",
       "278   중국 우한폐렴 확산: 1H20 위축→2H20 회복 / PE 수요 전망치 하향 조정...      0\n",
       "\n",
       "[279 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "nonpreprocesses = list(df[\"document\"])\n",
    "docs = list(df[\"document\"])\n",
    "\n",
    "for idx, doc in enumerate(docs):\n",
    "    doc = re.sub(r\"\\s+\", \" \", doc)    \n",
    "    docs[idx] = doc\n",
    "\n",
    "for idx, (nonpreprocess, doc) in enumerate(zip(nonpreprocesses, docs)):\n",
    "    if idx == 3:\n",
    "        break\n",
    "\n",
    "    print(nonpreprocess)\n",
    "    print(\"-\" * 20)\n",
    "    print(doc)\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "df[\"document\"] = docs\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a43218c3-ba7e-4018-b827-776850f7ed28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n",
      "72\n",
      "1 : 0.477\n",
      "==============================\n",
      "38\n",
      "18\n",
      "1 : 0.474\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, valid_data = train_test_split(df, test_size=0.2, random_state=42, stratify=df[[\"labels\"]])\n",
    "print(train_data[train_data[\"labels\"]==1].count()[\"labels\"])\n",
    "print(train_data[train_data[\"labels\"]==0].count()[\"labels\"])\n",
    "print(f\"1 : {train_data[train_data['labels']==0].count()['labels'] / train_data[train_data['labels']==1].count()['labels']:.3f}\")\n",
    "print(\"=\" * 30)\n",
    "print(valid_data[valid_data[\"labels\"]==1].count()[\"labels\"])\n",
    "print(valid_data[valid_data[\"labels\"]==0].count()[\"labels\"])\n",
    "print(f\"1 : {valid_data[valid_data['labels']==0].count()['labels'] / valid_data[valid_data['labels']==1].count()['labels']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26c57ea1-ac03-45ac-ae75-74dc8d06362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(\"./data/train_data.csv\", index=False)\n",
    "valid_data.to_csv(\"./data/valid_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc24275f-6b4f-481b-8d70-2bb0f73ce3d5",
   "metadata": {},
   "source": [
    "## 분기점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcbb7d6d-130e-4767-9268-003c9da5cf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/kb-albert-char-base-v2 were not used when initializing AlbertModel: ['predictions.dense.bias', 'predictions.decoder.weight', 'predictions.dense.weight', 'predictions.LayerNorm.weight', 'predictions.decoder.bias', 'sop_classifier.classifier.weight', 'predictions.LayerNorm.bias', 'sop_classifier.classifier.bias', 'predictions.bias']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "kb_albert_model_path = \"./model/kb-albert-char-base-v2\"\n",
    "albert = AutoModel.from_pretrained(kb_albert_model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(kb_albert_model_path)\n",
    "\n",
    "tokenizer.truncation_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "704542e3-5e34-4075-bb19-3c702513c8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-114c92345cc0cb4b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-114c92345cc0cb4b/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e375118a5c9b41bbb03771e38503536d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d35b8a1eeaec4bc5975fe7cd7d57057f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-114c92345cc0cb4b/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "755841ec8e77409fb2fa6fcb1df71a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-2c597c9e5d38e84a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/piai/.cache/huggingface/datasets/csv/default-2c597c9e5d38e84a/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0847089462594566bb70ed1f22c07932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3ac4d2cf48e421cb26fa3d70b3f914c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/piai/.cache/huggingface/datasets/csv/default-2c597c9e5d38e84a/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc18ac0aeb1641a09b254a5fdf7e4ca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ef6daf6d03c44f5844285762459eeb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/223 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a20b67955eb4f3db3551b2354748090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "MAX_LEN = 512\n",
    "\n",
    "def tokenized_fn(data):\n",
    "    outputs = tokenizer(data[\"document\"], padding=\"max_length\", max_length=MAX_LEN, truncation=True)\n",
    "    outputs[\"labels\"] = data[\"labels\"]\n",
    "    return outputs\n",
    "\n",
    "train_dataset = load_dataset(\"csv\", data_files=\"./data/train_data.csv\")[\"train\"]\n",
    "valid_dataset = load_dataset(\"csv\", data_files=\"./data/valid_data.csv\")[\"train\"]\n",
    "\n",
    "train_dataset = train_dataset.map(tokenized_fn, remove_columns=[\"document\"])\n",
    "valid_dataset = valid_dataset.map(tokenized_fn, remove_columns=[\"document\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7aa0a7c-ad41-4dd0-a225-91dc562cdf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_input_ids = list()\n",
    "# list_token_type_ids = list()\n",
    "# list_attention_mask = list()\n",
    "# for idx, doc in enumerate(df[\"document\"]):\n",
    "#     tokenized_doc = tokenizer(doc, padding=\"max_length\", max_length=MAX_LEN, truncation=True)\n",
    "#     list_input_ids.append(tokenized_doc[\"input_ids\"])\n",
    "#     list_token_type_ids.append(tokenized_doc[\"token_type_ids\"])\n",
    "#     list_attention_mask.append(tokenized_doc[\"attention_mask\"])\n",
    "\n",
    "# df[\"input_ids\"] = list_input_ids\n",
    "# df[\"token_type_ids\"] = list_token_type_ids\n",
    "# df[\"attention_mask\"] = list_attention_mask\n",
    "# df = df[[\"document\", \"input_ids\", \"token_type_ids\", \"attention_mask\", \"labels\"]]\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8132047-123e-4679-a4d8-8ec5ee5a45d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.dense1 = torch.nn.Linear(768, 3072)\n",
    "        self.dropout = torch.nn.Dropout(0.25)\n",
    "        # self.dense2 = torch.nn.Linear(3072, 768)\n",
    "        self.out_proj = torch.nn.Linear(768, 2)\n",
    "    \n",
    "    def forward(self, features):\n",
    "        # 보통 분류기에선 start 토큰에 분류 결과를 담음\n",
    "        x = features[:, 0, :]    # take <s> token (equiv. to [CLS])\n",
    "        x = x.reshape(-1, x.size(-1))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "#         x = self.dense1(x)\n",
    "#         x = torch.relu(x)\n",
    "#         x = self.dropout(x)\n",
    "        \n",
    "#         x = self.dense2(x)\n",
    "#         x = torch.tanh(x)\n",
    "#         x = self.dropout(x)\n",
    "        x = self.out_proj(x)\n",
    "        return x\n",
    "\n",
    "class AInalyst(torch.nn.Module):\n",
    "    def __init__(self, pretrained_model):\n",
    "        super(AInalyst, self).__init__()\n",
    "        self.pretrained = pretrained_model\n",
    "        self.classifier = ClassificationHead()\n",
    "    \n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None):\n",
    "        outputs = self.pretrained(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            # labels=labels\n",
    "        )\n",
    "        self.labels = labels\n",
    "        logits = self.classifier(outputs[\"last_hidden_state\"])\n",
    "        # prob = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        \n",
    "        if labels is not None:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits, labels)\n",
    "            return logits, loss\n",
    "        else:\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c521e3-4e7f-465e-923c-5958b5add4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def crossvalid(model=None, criterion=None, optimizer=None, dataset=None, k_fold=5):\n",
    "#     total_size = len(dataset)\n",
    "#     fraction = 1/k_fold\n",
    "#     seg = int(total_size * fraction)\n",
    "    \n",
    "#     for idx in range(k_fold):\n",
    "#         trill = 0\n",
    "#         trilr = idx * seg\n",
    "#         vall = trill\n",
    "#         valr = i * seg + seg\n",
    "#         trirl = valr\n",
    "#         trirr = total_size\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12fb4767-ffab-4de0-9577-9d3ee7c42dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "weight = torch.tensor([0.5, 0.5]).to(device)\n",
    "loss_fct = torch.nn.CrossEntropyLoss(weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8268da5-a1c1-446f-a07a-95b45b928ee2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): AInalyst(\n",
       "    (pretrained): AlbertModel(\n",
       "      (embeddings): AlbertEmbeddings(\n",
       "        (word_embeddings): Embedding(9607, 128, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 128)\n",
       "        (token_type_embeddings): Embedding(2, 128)\n",
       "        (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (encoder): AlbertTransformer(\n",
       "        (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
       "        (albert_layer_groups): ModuleList(\n",
       "          (0): AlbertLayerGroup(\n",
       "            (albert_layers): ModuleList(\n",
       "              (0): AlbertLayer(\n",
       "                (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (attention): AlbertAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (attention_dropout): Dropout(p=0, inplace=False)\n",
       "                  (output_dropout): Dropout(p=0, inplace=False)\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                )\n",
       "                (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (activation): GELUActivation()\n",
       "                (dropout): Dropout(p=0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (pooler_activation): Tanh()\n",
       "    )\n",
       "    (classifier): ClassificationHead(\n",
       "      (dropout): Dropout(p=0.25, inplace=False)\n",
       "      (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AInalyst(pretrained_model=albert)\n",
    "model.to(device)\n",
    "model = torch.nn.DataParallel(model)\n",
    "isParallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b3b2387-f5f9-4630-b4ec-6eebbd9a9ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f7ca000-8d44-4a3c-95fe-9b5739c8e926",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    sampler = torch.utils.data.RandomSampler(train_dataset),\n",
    "    batch_size = batch_size,\n",
    "    collate_fn = data_collator,\n",
    ")\n",
    "\n",
    "validation_dataloader = torch.utils.data.DataLoader(\n",
    "    valid_dataset,\n",
    "    sampler = torch.utils.data.SequentialSampler(valid_dataset),\n",
    "    batch_size = batch_size,\n",
    "    collate_fn = data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "856c0eac-0f21-4b52-945c-bbd516799c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e8de932-6bff-4467-9ed8-3dfadf4a71b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8802fb07-5385-4992-8273-77b1db2ddc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Epoch 1/5 ======\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piai/anaconda3/envs/iml/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Average training loss: 0.60423\n",
      "\n",
      "Running Validation...\n",
      "Accuracy: 0.83929\n",
      "====== Epoch 2/5 ======\n",
      "Training...\n",
      "\n",
      " Average training loss: 0.36057\n",
      "\n",
      "Running Validation...\n",
      "Accuracy: 0.80357\n",
      "====== Epoch 3/5 ======\n",
      "Training...\n",
      "\n",
      " Average training loss: 0.13907\n",
      "\n",
      "Running Validation...\n",
      "Accuracy: 0.83929\n",
      "====== Epoch 4/5 ======\n",
      "Training...\n",
      "\n",
      " Average training loss: 0.04655\n",
      "\n",
      "Running Validation...\n",
      "Accuracy: 0.94643\n",
      "====== Epoch 5/5 ======\n",
      "Training...\n",
      "\n",
      " Average training loss: 0.01786\n",
      "\n",
      "Running Validation...\n",
      "Accuracy: 0.94643\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"====== Epoch {epoch+1}/{epochs} ======\")\n",
    "    print(\"Training...\")\n",
    "    \n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch_input_ids = batch[\"input_ids\"].to(device)\n",
    "        batch_attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        batch_labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        logits, loss = model(\n",
    "            input_ids = batch_input_ids,\n",
    "            attention_mask = batch_attention_mask,\n",
    "            labels = batch_labels,\n",
    "        )\n",
    "        \n",
    "        # # output 모양 출력해보기\n",
    "        # outputs = model(\n",
    "        #     input_ids = batch_input_ids,\n",
    "        #     attention_mask = batch_attention_mask,\n",
    "        #     labels = batch_labels,\n",
    "        # )\n",
    "        # print(\"print outputs : \")\n",
    "        # print(outputs)\n",
    "        # print(outputs.last_hidden_state.shape)\n",
    "        # break\n",
    "    \n",
    "        if isParallel:\n",
    "            loss = loss.mean()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        if step % 1000 == 0 and not step == 0:\n",
    "            print(\"step : {:>5,} of {:>5,} loss: {:.5f}\".format(step, len(train_dataloader), loss.item()))\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    print()\n",
    "    print(\" Average training loss: {0:.5f}\".format(avg_train_loss))\n",
    "    \n",
    "    # Validation\n",
    "    print()\n",
    "    print(\"Running Validation...\")\n",
    "    \n",
    "    model.eval()\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    \n",
    "    for step, batch in enumerate(validation_dataloader):\n",
    "        batch_input_ids = batch[\"input_ids\"].to(device)\n",
    "        batch_attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        batch_labels = batch[\"labels\"].to(device)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            logits, loss = model(\n",
    "                input_ids = batch_input_ids,\n",
    "                attention_mask = batch_attention_mask,\n",
    "                labels = batch_labels,\n",
    "            )\n",
    "            \n",
    "            if isParallel:\n",
    "                loss = loss.mean()\n",
    "            \n",
    "            total_eval_loss += loss.item()\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = batch_labels.to(\"cpu\").numpy()\n",
    "            total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"Accuracy: {0:.5f}\".format(avg_val_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a94aae-d6fe-4be3-9cbe-60637e2ecec4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
